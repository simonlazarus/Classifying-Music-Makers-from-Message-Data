{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d560c6f-c10f-4d48-951e-bd465184dc2d",
   "metadata": {},
   "source": [
    "# Summary of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363e9a9d-bae2-4a59-bb31-07da0c323c93",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8a4931b0-b0d8-4a07-8d5d-a1f271717802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "\n",
    "\n",
    "\n",
    "#Import functions and preprocessors from previous notebook\n",
    "from processing_functions import url_preprocessor, stem_processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcc3eea-65e0-4181-9970-f357e1a70247",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a95ba97b-183a-4bdb-b252-b890881a5136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2325 entries, 107hfj5 to 10b33q8\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   title        2325 non-null   object \n",
      " 1   text         2325 non-null   object \n",
      " 2   utc          2325 non-null   float64\n",
      " 3   subreddit    2325 non-null   object \n",
      " 4   title_words  2325 non-null   int64  \n",
      " 5   text_words   2325 non-null   int64  \n",
      " 6   title_chars  2325 non-null   int64  \n",
      " 7   text_chars   2325 non-null   int64  \n",
      "dtypes: float64(1), int64(4), object(3)\n",
      "memory usage: 163.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv('../data/combined.csv', index_col='id')\n",
    "\n",
    "#Since Pandas converts empty strings to NaN's, we need to fill these in again\n",
    "df_all.fillna('', inplace=True)\n",
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ed9473-6264-47b8-ad79-50c62eba3ddc",
   "metadata": {},
   "source": [
    "## Add a column that combines title and body text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9c4f728-6675-4041-b826-267be0d60212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title_words</th>\n",
       "      <th>text_words</th>\n",
       "      <th>title_chars</th>\n",
       "      <th>text_chars</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107hfj5</th>\n",
       "      <td>minature series</td>\n",
       "      <td>Over 2022, I wrote about 30 little pieces for ...</td>\n",
       "      <td>1.673279e+09</td>\n",
       "      <td>Composers</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>15</td>\n",
       "      <td>657</td>\n",
       "      <td>minature series Over 2022, I wrote about 30 li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107hah0</th>\n",
       "      <td>How can I get my music published?</td>\n",
       "      <td>I tried being \"my own\" publisher on ASCAP but ...</td>\n",
       "      <td>1.673278e+09</td>\n",
       "      <td>Composers</td>\n",
       "      <td>8</td>\n",
       "      <td>142</td>\n",
       "      <td>33</td>\n",
       "      <td>613</td>\n",
       "      <td>How can I get my music published? I tried bein...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     title  \\\n",
       "id                                           \n",
       "107hfj5                    minature series   \n",
       "107hah0  How can I get my music published?   \n",
       "\n",
       "                                                      text           utc  \\\n",
       "id                                                                         \n",
       "107hfj5  Over 2022, I wrote about 30 little pieces for ...  1.673279e+09   \n",
       "107hah0  I tried being \"my own\" publisher on ASCAP but ...  1.673278e+09   \n",
       "\n",
       "         subreddit  title_words  text_words  title_chars  text_chars  \\\n",
       "id                                                                     \n",
       "107hfj5  Composers            2         128           15         657   \n",
       "107hah0  Composers            8         142           33         613   \n",
       "\n",
       "                                                      post  \n",
       "id                                                          \n",
       "107hfj5  minature series Over 2022, I wrote about 30 li...  \n",
       "107hah0  How can I get my music published? I tried bein...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['post'] = df_all[['title','text']].apply((lambda x : ' '.join(x)), axis=1)\n",
    "df_all.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902d6fe4-113a-402b-9b90-a0a180500da5",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "\n",
    "We reserve 20% of our data in the dataframe `val_df`.  The remaining 80% of the data will be used to train our models; we will store this data in the dataframe `df`.  We will not use the `val_df` data until the validation stage at the end of the modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "329e04cb-a53f-4f27-b608-7fb655f3d07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Producers    930\n",
       "Composers    813\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, val_df = train_test_split(df_all,\n",
    "                               random_state=123,\n",
    "                               stratify=df_all['subreddit'])\n",
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2456e939-99b7-43f4-b59f-982323e54e94",
   "metadata": {},
   "source": [
    "## Baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16125abe-5db6-409a-bffa-d10c354e5ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Producers    0.533563\n",
       "Composers    0.466437\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2afa2f6-94c9-4056-bcf8-4672ce4e086d",
   "metadata": {},
   "source": [
    "So if we used a null model that just guessed the most common class (\"Producers\") in all cases, our accuracy score would be about 53.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba0187f-9c70-436a-a55d-36583d59442c",
   "metadata": {},
   "source": [
    "# Training models on title + body text\n",
    "\n",
    "We'll begin by training models on both the titles and body texts of posts, but no other features.  Later we will try training the models on other sets of features, such as using just the titles instead of titles+body texts, and also including word counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c9fbe8d-b73d-491a-a749-543a8e9c847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['post']\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efd0b0a-2b51-4289-9f8e-e4778e9fc3a5",
   "metadata": {},
   "source": [
    "We will train the following types of classification models: Naive Bayes, Logistic Regression, $k$-Nearest Neighbors (kNN), Random Forest, and Gradient Boosted Decision Trees.  For each type of model, we will perform a hyperparameter grid search to find the model that achieves the highest cross-val Accuracy score.  Based on the results of previous grid searches, we'll adapt the hyperparameters over which we're grid searching.  Finally, we'll go back to any models that performed well and more finely tune their hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9307afa2-0fe3-4a2d-b5b5-f4fde30d6ef8",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daed7d29-fec7-489e-881a-a7ff45e62f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=stopwords.words('english'))),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44199397-0fb9-4731-abd5-188aadc1f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipe_params = {\n",
    "    'cvec__preprocessor': [url_preprocessor, ( lambda x : stem_processor(url_preprocessor(x)) )],\n",
    "    'cvec__max_features': list(range(1000,5001,1000)),\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.5, .7, 0.9],\n",
    "    'cvec__ngram_range': [(1, 1), (1, 2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a239983e-1810-40d5-beed-c9a34865e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_gs = GridSearchCV(nb_pipe, param_grid = nb_pipe_params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db1837fe-d71a-46d0-bc93-cd1640af18c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    \"you're\",\n",
       "                                                                    \"you've\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it',\n",
       "                                                                    \"it's\",\n",
       "                                                                    'its',\n",
       "                                                                    'itself', ...])),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.5, 0.7, 0.9],\n",
       "                         'cvec__max_features': [1000, 2000, 3000, 4000, 5000],\n",
       "                         'cvec__min_df': [2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'cvec__preprocessor': [<function url_preprocessor at 0x7fb4990e2af0>,\n",
       "                                                <function <lambda> at 0x7fb4a01f35e0>]})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e400acea-c45b-462a-b877-b83fc31fae39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.5,\n",
       " 'cvec__max_features': 4000,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__preprocessor': <function processing_functions.url_preprocessor(text)>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine best hyperparameters but don't print the whole list of stopwords\n",
    "nb_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b479e73c-b488-46ed-8c51-44a6542a318b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9357375753384053"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7e1c41-9c07-4b37-a2ac-e43f4bd07fc7",
   "metadata": {},
   "source": [
    "This is a good crossval score!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ec5633-06b4-4be8-b15f-4e5352c2caa9",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8386d8c6-f431-4d8a-b2d3-39183c4b372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=stopwords.words('english'))),\n",
    "    ('ss',StandardScaler(with_mean=False)),\n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b3c12ea-bbfb-4b3e-a3be-2c9576766b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe_params = {\n",
    "    'lr__C' : np.logspace(-2,2,12),\n",
    "    \n",
    "    'cvec__preprocessor': [url_preprocessor, ( lambda x : stem_processor(url_preprocessor(x)) )],\n",
    "    'cvec__max_features': list(range(1000,5001,1000)),\n",
    "    'cvec__min_df': [2],\n",
    "    'cvec__max_df': [.5, .7, 0.9],\n",
    "    'cvec__ngram_range': [(1, 1), (1, 2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f9a0256-1a9e-4fea-b39f-004d6108a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gs = GridSearchCV(lr_pipe, lr_pipe_params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d3e1372-4448-4c64-95d1-456e84df9367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    \"you're\",\n",
       "                                                                    \"you've\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it',\n",
       "                                                                    \"it's\",\n",
       "                                                                    'its',\n",
       "                                                                    'itself', ...])),\n",
       "                                       ('ss', StandardScaler(with_mean=False)),\n",
       "                                       ('lr'...\n",
       "                         'cvec__min_df': [2],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'cvec__preprocessor': [<function url_preprocessor at 0x7fb4990e2af0>,\n",
       "                                                <function <lambda> at 0x7fb4b89bd280>],\n",
       "                         'lr__C': array([1.00000000e-02, 2.31012970e-02, 5.33669923e-02, 1.23284674e-01,\n",
       "       2.84803587e-01, 6.57933225e-01, 1.51991108e+00, 3.51119173e+00,\n",
       "       8.11130831e+00, 1.87381742e+01, 4.32876128e+01, 1.00000000e+02])})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gs.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0608937b-0b6e-4adf-9d92-aba6204aa32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.5,\n",
       " 'cvec__max_features': 1000,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__preprocessor': <function processing_functions.url_preprocessor(text)>,\n",
       " 'lr__C': 0.01}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4396c4ae-aa68-43e9-9609-c16699fd707a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9093419622566941"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06c32c7-5ffe-4708-adff-cb7d517d3976",
   "metadata": {},
   "source": [
    "This crossval score is still pretty good, but not as good as the Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bddc58-0211-4c34-8162-1c9a91fa462a",
   "metadata": {},
   "source": [
    "### What we've learned so far\n",
    "\n",
    "It seems that `CountVectorizer`'s parameters `min_df` being 2 works better than it being 3.  We'll try 1 as well (below).  Also, it seems that an `ngram_range` of `(1,1)` - i.e., the default of considering only single words - is generally best.  So for now, we'll save some computation time and set these parameters to these values.  Similarly, adding stemming (on top of the URL preprocessor) didn't seem to help in any case so far, so we'll stop using it.\n",
    "\n",
    "Finally, `max_df` seems to be too large to be relevant (perhaps because no word appears in more than 50% of posts): both of the above gridsearches found the optimal `max_df` to be .5.  Any value smaller than this certainly defeats the point of having a `max_df`, so we'll drop this parameter.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b2d826-ec47-4f89-8262-a895e5dffb4e",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6faa148e-fb57-4bca-a7c3-cb867eaab9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=stopwords.words('english'), preprocessor = url_preprocessor) ),\n",
    "    ('ss', StandardScaler(with_mean=False)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa0b1a41-4c74-458f-9357-3cbb80c1c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe_params = {\n",
    "    'knn__n_neighbors':[3,5,7,9],\n",
    "    'knn__weights':['uniform','distance'],\n",
    "    \n",
    "    'cvec__max_features': list(range(1000,5001,1000)),\n",
    "    'cvec__min_df': [1,2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe7cd953-9e45-49f8-b552-3650166d61aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_gs = GridSearchCV(knn_pipe, param_grid = knn_pipe_params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "751a0f41-4cd7-44c7-91ff-caa7edcda393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(preprocessor=<function url_preprocessor at 0x7fb4990e2af0>,\n",
       "                                                        stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    \"you're\",\n",
       "                                                                    \"you've\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it',\n",
       "                                                                    \"it's\",\n",
       "                                                                    'its',\n",
       "                                                                    'itself', ...])),\n",
       "                                       ('ss', StandardScaler(with_mean=False)),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_features': [1000, 2000, 3000, 4000, 5000],\n",
       "                         'cvec__min_df': [1, 2],\n",
       "                         'knn__n_neighbors': [3, 5, 7, 9],\n",
       "                         'knn__weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97fd7e1f-bd78-484b-9d65-6452275b03bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 1000,\n",
       " 'cvec__min_df': 2,\n",
       " 'knn__n_neighbors': 3,\n",
       " 'knn__weights': 'uniform'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72096fc6-4416-475e-9e35-5171234d7bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.763648190231532"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091f7ef3-be43-4ced-9c7f-b823a75b7aca",
   "metadata": {},
   "source": [
    "So again we find that `min_df=2` is best.  So next time, we'll drop `min_df=3` from consideration, but we'll also try `min_df=.01` (i.e., keep only those words that appear in at least 1% of posts).\n",
    "\n",
    "This score is not nearly as good as the other models, so we won't bother with a more refined search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad0bb2e-b933-4d6a-a2b3-ea5456fcdd86",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f896331f-b2cf-49aa-9e89-a16b84aef634",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=stopwords.words('english'), preprocessor = url_preprocessor) ),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5005aefb-d6bb-46d9-9407-8ee981dbe227",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe_params = {\n",
    "    'rf__n_estimators':[50,100,150],\n",
    "    'rf__max_depth':[None,5],\n",
    "    'rf__min_samples_split':[2,5,10],\n",
    "    'rf__ccp_alpha':[0,.01,.1],\n",
    "    \n",
    "    'cvec__max_features': list(range(1000,5001,1000)),\n",
    "    'cvec__min_df': [2,.01],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8d967b2b-b0af-4885-aa86-5fab1c21ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gs = GridSearchCV(rf_pipe, param_grid = rf_pipe_params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2a95b95a-eb74-41d7-a52c-e9df0927b78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(preprocessor=<function url_preprocessor at 0x7fb4990e2af0>,\n",
       "                                                        stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    \"you're\",\n",
       "                                                                    \"you've\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it',\n",
       "                                                                    \"it's\",\n",
       "                                                                    'its',\n",
       "                                                                    'itself', ...])),\n",
       "                                       ('rf',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_features': [1000, 2000, 3000, 4000, 5000],\n",
       "                         'cvec__min_df': [2, 0.01],\n",
       "                         'rf__ccp_alpha': [0, 0.01, 0.1],\n",
       "                         'rf__max_depth': [None, 5],\n",
       "                         'rf__min_samples_split': [2, 5, 10],\n",
       "                         'rf__n_estimators': [50, 100, 150]})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "85d23f87-40cc-4857-be04-08f42b872f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 2000,\n",
       " 'cvec__min_df': 2,\n",
       " 'rf__ccp_alpha': 0,\n",
       " 'rf__max_depth': None,\n",
       " 'rf__min_samples_split': 10,\n",
       " 'rf__n_estimators': 150}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "751ef622-cb2a-469c-8b0b-2a1ea2d866f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9225290649804038"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1def0e-1d56-4087-9576-0d525bc5cb1e",
   "metadata": {},
   "source": [
    "Again, this is a pretty good score.  And again we find that `min_df=2` seems to be working best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195882f8-d240-4f61-8c72-ac8e55f0e70d",
   "metadata": {},
   "source": [
    "# Gradient Boosted Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2aee6ed1-4611-40e0-944e-d2eb25d2707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=stopwords.words('english'), preprocessor = url_preprocessor) ),\n",
    "    ('ss', StandardScaler(with_mean=False)),\n",
    "    ('boost', GradientBoostingClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e8229efc-b94f-4f19-b017-4d7c11281072",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_pipe_params = {\n",
    "    'boost__n_estimators': list(range(40,161,20)),\n",
    "    'boost__max_depth': [3,4],\n",
    "\n",
    "    \n",
    "    'cvec__max_features': [1000,2000,3000,4000,5000],\n",
    "    'cvec__min_df': [2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e4e2920c-9a5a-4d5e-8b08-718c050fd3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_gs = GridSearchCV(boost_pipe, param_grid = boost_pipe_params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0d16c3e6-59f3-45e1-8e8b-e232a8d351a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(preprocessor=<function url_preprocessor at 0x7fb4990e2af0>,\n",
       "                                                        stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    \"you're\",\n",
       "                                                                    \"you've\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it',\n",
       "                                                                    \"it's\",\n",
       "                                                                    'its',\n",
       "                                                                    'itself', ...])),\n",
       "                                       ('ss', StandardScaler(with_mean=False)),\n",
       "                                       ('boost',\n",
       "                                        GradientBoostingClassifier(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'boost__max_depth': [3, 4],\n",
       "                         'boost__n_estimators': [40, 60, 80, 100, 120, 140,\n",
       "                                                 160],\n",
       "                         'cvec__max_features': [1000, 2000, 3000, 4000, 5000],\n",
       "                         'cvec__min_df': [2]})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "855c8560-7fbd-4c6b-97e1-554a7c07210e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boost__max_depth': 4,\n",
       " 'boost__n_estimators': 160,\n",
       " 'cvec__max_features': 1000,\n",
       " 'cvec__min_df': 2}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "39502888-bfbd-47c0-af49-a4e4b4cb31c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9087721898363139"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0678495b-478c-4d42-83d9-6f958667a6e7",
   "metadata": {},
   "source": [
    "# Refining the models\n",
    "\n",
    "We'll refine the models in the reverse order from the order in which we originally trained them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea97061-0e9f-4454-bd1b-ea6cbd33b654",
   "metadata": {},
   "source": [
    "### Gradient Boosted Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0f259aaa-4e41-44b0-a349-89f3fb4754f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjusting learning rate before further refining\n",
    "boost_pipe_params0 = {\n",
    "    'boost__n_estimators': [50,100,150,200],\n",
    "    'boost__max_depth': [3,4,5],\n",
    "    'boost__learning_rate': np.logspace(-3,-1,8),\n",
    "    \n",
    "    'cvec__max_features': [500,1000,1500,2000],\n",
    "    'cvec__min_df': [2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ac7d3be6-0fa6-40b9-8b72-773e800dbab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_gs0 = GridSearchCV(boost_pipe, param_grid = boost_pipe_params0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "61606bfa-b3ff-42a8-a112-51211cac6fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(preprocessor=<function url_preprocessor at 0x7fb4990e2af0>,\n",
       "                                                        stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    \"you're\",\n",
       "                                                                    \"you've\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it',\n",
       "                                                                    \"it's\",\n",
       "                                                                    'its',\n",
       "                                                                    'its...\n",
       "                                       ('ss', StandardScaler(with_mean=False)),\n",
       "                                       ('boost',\n",
       "                                        GradientBoostingClassifier(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'boost__learning_rate': array([0.001     , 0.0019307 , 0.00372759, 0.00719686, 0.01389495,\n",
       "       0.02682696, 0.05179475, 0.1       ]),\n",
       "                         'boost__max_depth': [3, 4, 5],\n",
       "                         'boost__n_estimators': [50, 100, 150, 200],\n",
       "                         'cvec__max_features': [500, 1000, 1500, 2000],\n",
       "                         'cvec__min_df': [2]})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_gs0.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5f96295d-5669-44a3-9b35-4b5b47a819ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boost__learning_rate': 0.1,\n",
       " 'boost__max_depth': 5,\n",
       " 'boost__n_estimators': 200,\n",
       " 'cvec__max_features': 1000,\n",
       " 'cvec__min_df': 2}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_gs0.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fb729305-8a03-4213-b3d5-51caaf2361ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9139363699239207"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_gs0.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704dd77e-5321-4e64-a2d2-33fa8bf42c64",
   "metadata": {},
   "source": [
    "This model did somewhat better than the last one, but playing with the `learning_rate` did not help.  We'll use this information to look for a more refined model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7425babd-97d0-49c2-92de-19c9417b667d",
   "metadata": {},
   "source": [
    "#### Refining again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c50119bd-3fa8-4b48-8130-35170176a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjusting learning rate before further refining\n",
    "boost_pipe_params1 = {\n",
    "    'boost__n_estimators': list(range(150,221,10)),\n",
    "    'boost__max_depth': [4,5,6,7],\n",
    "    \n",
    "    'cvec__max_features': [700,800,900,1000,1100,1200],\n",
    "    'cvec__min_df': [2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cb182d97-5aa2-41bd-bb34-ec2606acdc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_gs1 = GridSearchCV(boost_pipe, param_grid = boost_pipe_params1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "39ba6220-d128-4478-95bf-113b65f0abbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(preprocessor=<function url_preprocessor at 0x7fb4990e2af0>,\n",
       "                                                        stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    \"you're\",\n",
       "                                                                    \"you've\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it',\n",
       "                                                                    \"it's\",\n",
       "                                                                    'its',\n",
       "                                                                    'itself', ...])),\n",
       "                                       ('ss', StandardScaler(with_mean=False)),\n",
       "                                       ('boost',\n",
       "                                        GradientBoostingClassifier(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'boost__max_depth': [4, 5, 6, 7],\n",
       "                         'boost__n_estimators': [150, 160, 170, 180, 190, 200,\n",
       "                                                 210, 220],\n",
       "                         'cvec__max_features': [700, 800, 900, 1000, 1100,\n",
       "                                                1200],\n",
       "                         'cvec__min_df': [2]})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_gs1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9bb65ac3-ac98-4327-9ce6-c2f454fd292d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boost__max_depth': 5,\n",
       " 'boost__n_estimators': 220,\n",
       " 'cvec__max_features': 1000,\n",
       " 'cvec__min_df': 2}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_gs1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a1a67fc7-f8a8-460b-bb7e-cc3c01870dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9139380166650198"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_gs1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0d2afc-557f-49a4-92d2-30903029e2bd",
   "metadata": {},
   "source": [
    "The improvement from the second round of refining was rather miniscule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3657a0e-c1d1-45c6-8930-c3655e7802d3",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Let's see if we can do any better.  We'll try adding back bigrams this time, as well as adding in `min_samples_leaf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67348630-fed9-491a-92c3-62c5363f730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe_params1 = {\n",
    "    'rf__n_estimators':[100, 150, 200, 250],\n",
    "    'rf__max_depth':[None,7],\n",
    "    'rf__min_samples_split':[5,10],\n",
    "    'rf__min_samples_leaf':[1,2,5,10],\n",
    "    \n",
    "    'cvec__max_features': [2500,3000,3500],\n",
    "    'cvec__min_df': [2],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4adae35f-514b-4024-a960-7fa7c8b2acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gs1 = GridSearchCV(rf_pipe, param_grid = rf_pipe_params1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c86009f-d02d-406c-ba76-13c1cc2e4e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(preprocessor=<function url_preprocessor at 0x7fb4990e2af0>,\n",
       "                                                        stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    \"you're\",\n",
       "                                                                    \"you've\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it',\n",
       "                                                                    \"it's\",\n",
       "                                                                    'its',\n",
       "                                                                    'itself', ...])),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_features': [2500, 3000, 3500],\n",
       "                         'cvec__min_df': [2],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'rf__max_depth': [None, 7],\n",
       "                         'rf__min_samples_leaf': [1, 2, 5, 10],\n",
       "                         'rf__min_samples_split': [5, 10],\n",
       "                         'rf__n_estimators': [100, 150, 200, 250]})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_gs1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab581b23-f912-4fa2-9482-17af8a9b28f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 3500,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'rf__max_depth': None,\n",
       " 'rf__min_samples_leaf': 1,\n",
       " 'rf__min_samples_split': 10,\n",
       " 'rf__n_estimators': 150}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_gs1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d531f5f8-8228-4b3d-a200-f46826bc4c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9225241247571058"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_gs1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371da35f-eff4-4106-ac3b-09195151e387",
   "metadata": {},
   "source": [
    "This more refined search didn't improve the score all that much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0167bbb4-f584-43b2-9979-d6a3b7014021",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb4d6484-0365-493a-adae-be12b49dafe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=stopwords.words('english'), preprocessor = url_preprocessor) ),\n",
    "    ('ss',StandardScaler(with_mean=False)),\n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ad9e6f3-38a3-4fe1-80a6-659b1e336235",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe_params1 = {\n",
    "    'lr__C' : np.logspace(-3,2,20),\n",
    "\n",
    "    'cvec__max_features': [250, 500, 750, 1000, 1250, 1500, 1750, 2000],\n",
    "    'cvec__min_df': [2],\n",
    "    'cvec__ngram_range': [(1, 1), (1, 2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "938ba487-78df-4c72-8baf-25eae72ccee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gs1 = GridSearchCV(lr_pipe, lr_pipe_params1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e211c664-be64-4566-9d7b-d5919a556337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(preprocessor=<function url_preprocessor at 0x7fb4990e2af0>,\n",
       "                                                        stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    \"you're\",\n",
       "                                                                    \"you've\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it',\n",
       "                                                                    \"it's\",\n",
       "                                                                    'its',\n",
       "                                                                    'its...\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'lr__C': array([1.00000000e-03, 1.83298071e-03, 3.35981829e-03, 6.15848211e-03,\n",
       "       1.12883789e-02, 2.06913808e-02, 3.79269019e-02, 6.95192796e-02,\n",
       "       1.27427499e-01, 2.33572147e-01, 4.28133240e-01, 7.84759970e-01,\n",
       "       1.43844989e+00, 2.63665090e+00, 4.83293024e+00, 8.85866790e+00,\n",
       "       1.62377674e+01, 2.97635144e+01, 5.45559478e+01, 1.00000000e+02])})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gs1.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "366aa47c-2074-4758-a2be-ac88e3c7014f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 1750,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'lr__C': 0.006158482110660267}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gs1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "72f8c26f-1b18-49d0-9b2a-1455ceb02a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9110743338932252"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gs1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64df6bd7-5b76-4d70-bd8d-fba087d44931",
   "metadata": {},
   "source": [
    "Again, the more refined search did not improve the accuracy score much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4770f6-7b84-4dd8-8439-4592e37aa25d",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7538da68-ab4b-4b10-b4ea-11275defcffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=stopwords.words('english'), preprocessor = url_preprocessor) ),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f92e5c11-6223-48c0-8a7b-47efef17e733",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipe_params1 = {\n",
    "    'nb__alpha': np.logspace(-2,2,9),\n",
    "    \n",
    "    'cvec__max_features': list(range(3250,4751,250)),\n",
    "    'cvec__min_df': [2],\n",
    "    'cvec__ngram_range': [(1, 1), (1, 2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f942be8d-a051-47fb-ae5f-cdf60181f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_gs1 = GridSearchCV(nb_pipe, param_grid = nb_pipe_params1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "59817033-c3bb-4965-b33d-e8bd6a74a219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(preprocessor=<function url_preprocessor at 0x7fb4990e2af0>,\n",
       "                                                        stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    \"you're\",\n",
       "                                                                    \"you've\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it',\n",
       "                                                                    \"it's\",\n",
       "                                                                    'its',\n",
       "                                                                    'itself', ...])),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_features': [3250, 3500, 3750, 4000, 4250,\n",
       "                                                4500, 4750],\n",
       "                         'cvec__min_df': [2],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'nb__alpha': array([1.00000000e-02, 3.16227766e-02, 1.00000000e-01, 3.16227766e-01,\n",
       "       1.00000000e+00, 3.16227766e+00, 1.00000000e+01, 3.16227766e+01,\n",
       "       1.00000000e+02])})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_gs1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8cb88356-1f05-4610-af10-a179b9dbe9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 3750,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'nb__alpha': 1.0}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine best hyperparameters but don't print the whole list of stopwords\n",
    "nb_gs1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d7149bd4-d2de-483e-9da8-d691dcb4c36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9363106412409842"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_gs1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd7f51e-bd26-4e91-af85-f3bbb0f27b76",
   "metadata": {},
   "source": [
    "Again, the improvement is rather small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae371f13-f598-49ba-986d-94daf5ea3f37",
   "metadata": {},
   "source": [
    "# Summary of best models trained on titles + body text\n",
    "\n",
    "So far, to avoid data leakage, we haven't touched the test data.  But to summarize our progress so far, we'll make a table of the crossval accuracy scores and test data accuracy scores of the best models so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f93bde03-6eb2-4d2e-b98b-cc7264b5c902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crossval Score</th>\n",
       "      <th>Test Data Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.936311</td>\n",
       "      <td>0.917526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.922524</td>\n",
       "      <td>0.914089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boost</th>\n",
       "      <td>0.913938</td>\n",
       "      <td>0.908935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.911074</td>\n",
       "      <td>0.903780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Crossval Score  Test Data Score\n",
       "Naive Bayes                0.936311         0.917526\n",
       "Random Forest              0.922524         0.914089\n",
       "Gradient Boost             0.913938         0.908935\n",
       "Logistic Regression        0.911074         0.903780"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_dict = {'nb_gs1': 'Naive Bayes',\n",
    "              'rf_gs1': 'Random Forest',\n",
    "              'lr_gs1': 'Logistic Regression',\n",
    "              'boost_gs1':'Gradient Boost'}\n",
    "\n",
    "X_test = val_df['post']\n",
    "y_test = val_df['subreddit']\n",
    "\n",
    "results_dict = {}\n",
    "for est in names_dict.keys():\n",
    "    results_dict[names_dict[est]] = {\n",
    "     'Crossval Score': locals()[est].best_score_,\n",
    "     'Test Data Score': locals()[est].score(X_test, y_test)\n",
    "    }\n",
    "    \n",
    "results_df = pd.DataFrame(results_dict).T\n",
    "results_df.sort_values('Crossval Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d1cbf-8f6e-4204-bc97-4c9fe849aee3",
   "metadata": {},
   "source": [
    "These models have performed rather well.  But would a stacked model, which combines their predictions, improve results even further?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15967d4c-fa5b-4ef7-804b-fa6209933da8",
   "metadata": {},
   "source": [
    "## Stacked Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "76c56604-7255-4b82-ad88-8c380ec54548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['nb_gs1', 'rf_gs1', 'lr_gs1', 'boost_gs1'])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3814b32c-5ccc-42b7-94fb-8d75e83be869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec',\n",
       "                 CountVectorizer(max_features=3750, min_df=2,\n",
       "                                 preprocessor=<function url_preprocessor at 0x7fb4990e2af0>,\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locals()['nb_gs1'].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "06a5e75f-396d-4e58-8b42-f4219d2a54c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nb_gs1', 'rf_gs1', 'lr_gs1', 'boost_gs1']\n"
     ]
    }
   ],
   "source": [
    "print(list(names_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6c43f5b3-b748-414b-9cc8-96f3d3d34ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following list comprehension won't work, as locals() is local to the most local scope (which is only the list comp here):\n",
    "#level1_estimators = [ (name, locals()[name].best_estimator_) for name in names_dict.keys()]\n",
    "\n",
    "level1_estimators = []\n",
    "for name in names_dict.keys():\n",
    "    level1_estimators.append((name, locals()[name].best_estimator_))\n",
    "\n",
    "stacked_model = StackingClassifier(estimators=level1_estimators,\n",
    "                                 final_estimator=LogisticRegression(penalty='none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fc2d3f3b-8e31-4b80-bf52-806bc3819bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = cross_val_score(stacked_model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8fc9ed30-a8e6-4678-b3c5-d96e10d224ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('nb_gs1',\n",
       "                                Pipeline(steps=[('cvec',\n",
       "                                                 CountVectorizer(max_features=3750,\n",
       "                                                                 min_df=2,\n",
       "                                                                 preprocessor=<function url_preprocessor at 0x7fb4990e2af0>,\n",
       "                                                                 stop_words=['i',\n",
       "                                                                             'me',\n",
       "                                                                             'my',\n",
       "                                                                             'myself',\n",
       "                                                                             'we',\n",
       "                                                                             'our',\n",
       "                                                                             'ours',\n",
       "                                                                             'ourselves',\n",
       "                                                                             'you',\n",
       "                                                                             \"you're\",\n",
       "                                                                             \"you've\",\n",
       "                                                                             \"you'll\",\n",
       "                                                                             \"you'd\",\n",
       "                                                                             'your',\n",
       "                                                                             'yours',\n",
       "                                                                             'yourself',\n",
       "                                                                             'yourselves',\n",
       "                                                                             'he',\n",
       "                                                                             'him',\n",
       "                                                                             'his',\n",
       "                                                                             'himself',\n",
       "                                                                             'she',\n",
       "                                                                             \"she's\",...\n",
       "                                                                             'you',\n",
       "                                                                             \"you're\",\n",
       "                                                                             \"you've\",\n",
       "                                                                             \"you'll\",\n",
       "                                                                             \"you'd\",\n",
       "                                                                             'your',\n",
       "                                                                             'yours',\n",
       "                                                                             'yourself',\n",
       "                                                                             'yourselves',\n",
       "                                                                             'he',\n",
       "                                                                             'him',\n",
       "                                                                             'his',\n",
       "                                                                             'himself',\n",
       "                                                                             'she',\n",
       "                                                                             \"she's\",\n",
       "                                                                             'her',\n",
       "                                                                             'hers',\n",
       "                                                                             'herself',\n",
       "                                                                             'it',\n",
       "                                                                             \"it's\",\n",
       "                                                                             'its',\n",
       "                                                                             'itself', ...])),\n",
       "                                                ('ss',\n",
       "                                                 StandardScaler(with_mean=False)),\n",
       "                                                ('boost',\n",
       "                                                 GradientBoostingClassifier(max_depth=5,\n",
       "                                                                            n_estimators=220,\n",
       "                                                                            random_state=42))]))],\n",
       "                   final_estimator=LogisticRegression(penalty='none'))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9dd9bbe9-37e0-45be-8b2d-c167b953bf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crossval Score</th>\n",
       "      <th>Test Data Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stacked Model</th>\n",
       "      <td>0.940327</td>\n",
       "      <td>0.931271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.936311</td>\n",
       "      <td>0.917526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.922524</td>\n",
       "      <td>0.914089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boost</th>\n",
       "      <td>0.913938</td>\n",
       "      <td>0.908935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.911074</td>\n",
       "      <td>0.903780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Crossval Score  Test Data Score\n",
       "Stacked Model              0.940327         0.931271\n",
       "Naive Bayes                0.936311         0.917526\n",
       "Random Forest              0.922524         0.914089\n",
       "Gradient Boost             0.913938         0.908935\n",
       "Logistic Regression        0.911074         0.903780"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict['Stacked Model'] = {\n",
    "     'Crossval Score': cvs.mean(),\n",
    "     'Test Data Score': stacked_model.score(X_test, y_test)\n",
    "    }\n",
    "\n",
    "results_df = pd.DataFrame(results_dict).T\n",
    "results_df.sort_values('Crossval Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cc077b-2ea0-4c79-8125-1c4d4068e7e7",
   "metadata": {},
   "source": [
    "# Training on Titles Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0ed7d3-806b-42be-93b3-071e84b2198d",
   "metadata": {},
   "source": [
    "For comparison, we'll train a Naive Bayes model on only the *titles* of the posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "44c7c8ac-b29e-401a-9563-1c9b2df4460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_title = df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "194b1358-6a6c-4847-9da1-f2833e8d4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_title_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=stopwords.words('english'), preprocessor = url_preprocessor) ),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "05c4ff35-94a2-41d3-b550-cd66d0ae09ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_title_pipe_params = {\n",
    "    'cvec__max_features': list(range(500,5001,500)),\n",
    "    'cvec__min_df': [2, .1],\n",
    "    'cvec__max_df': [.95, .9],\n",
    "    'cvec__ngram_range': [(1, 1), (1, 2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "61310b88-ce93-4006-9156-3865c4984a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_title_gs = GridSearchCV(nb_title_pipe, param_grid = nb_title_pipe_params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "23d30c71-9b19-4f40-b18d-30da30a7a756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(preprocessor=<function url_preprocessor at 0x7fb4990e2af0>,\n",
       "                                                        stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    \"you're\",\n",
       "                                                                    \"you've\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it',\n",
       "                                                                    \"it's\",\n",
       "                                                                    'its',\n",
       "                                                                    'itself', ...])),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.95, 0.9],\n",
       "                         'cvec__max_features': [500, 1000, 1500, 2000, 2500,\n",
       "                                                3000, 3500, 4000, 4500, 5000],\n",
       "                         'cvec__min_df': [2, 0.1],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_title_gs.fit(X_title, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fb1a21b1-abb4-4172-964c-52ba9f031a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.95,\n",
       " 'cvec__max_features': 1500,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine best hyperparameters but don't print the whole list of stopwords\n",
    "nb_title_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "00730e26-babd-46f5-b2e8-b7b57964edca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8468283766426243"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross-val score\n",
    "nb_title_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0ad77022-6653-4b9d-84b8-185d0a0fa5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8642611683848798"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test score\n",
    "X_test_title = val_df['title']\n",
    "nb_title_gs.score(X_test_title, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69fc29f-be40-403d-809b-406431f2df51",
   "metadata": {},
   "source": [
    "# Including word counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f972ba-bd98-4784-b8f4-7e00c7ae414d",
   "metadata": {},
   "source": [
    "Do our models perform better if we give them the title and body text word counts as features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "22ba0ca2-ed17-4e8b-870a-85acbbfee427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>title_words</th>\n",
       "      <th>text_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103osx2</th>\n",
       "      <td>halftime vs gross beat is there any audible di...</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoda66</th>\n",
       "      <td>First Composition, what do you think ? Hi. I'm...</td>\n",
       "      <td>8</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      post  title_words  \\\n",
       "id                                                                        \n",
       "103osx2  halftime vs gross beat is there any audible di...            4   \n",
       "zoda66   First Composition, what do you think ? Hi. I'm...            8   \n",
       "\n",
       "         text_words  \n",
       "id                   \n",
       "103osx2          30  \n",
       "zoda66           68  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_words = df[['post','title_words','text_words']]\n",
    "X_words_test = val_df[['post','title_words','text_words']]\n",
    "X_words.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "700c615f-4e8f-4412-8aab-b9f40994c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count vectorize only the 'post' column\n",
    "counter = ColumnTransformer(\n",
    " transformers=[\n",
    "     ('cvec', CountVectorizer(stop_words=stopwords.words('english'), preprocessor = url_preprocessor),  ['post']),\n",
    " ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cfbd28dd-95e3-456e-b585-abbd78183db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_words_pipe = Pipeline([\n",
    "    ('count', counter),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "69464ebc-7567-4f13-a1f3-9d4c0f67c573",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_words_pipe_params = {\n",
    "    'count__cvec__max_features': list(range(500,5001,500)),\n",
    "    'count__cvec__min_df': [2, .1],\n",
    "    #'count__cvec__max_df': [.95, .9],\n",
    "    'count__cvec__ngram_range': [(1, 1), (1, 2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "915f6b5f-debe-47e0-a686-5150d6288f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_words_gs = GridSearchCV(nb_words_pipe, param_grid = nb_words_pipe_params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7d9fe6fe-d33c-4ae1-8bc6-e358bc843eed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max_df corresponds to < documents than min_df",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5v/3x2_29n942n4k09n89jp09m80000gn/T/ipykernel_46042/3692445824.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnb_words_gs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \"\"\"\n\u001b[1;32m    389\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    349\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    604\u001b[0m         )\n\u001b[1;32m    605\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m             return Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    607\u001b[0m                 delayed(func)(\n\u001b[1;32m    608\u001b[0m                     \u001b[0mtransformer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    264\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    264\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1342\u001b[0m             )\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax_doc_count\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_doc_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_df corresponds to < documents than min_df\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max_df corresponds to < documents than min_df"
     ]
    }
   ],
   "source": [
    "nb_words_gs.fit(X_words, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1902098d-4698-4189-aaf3-cfa193828eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.95,\n",
       " 'cvec__max_features': 1500,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine best hyperparameters but don't print the whole list of stopwords\n",
    "nb_title_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7c66b02c-8e8e-47ab-a270-c96acab4c5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8468283766426243"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross-val score\n",
    "nb_title_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3decf7a8-2368-400c-9687-a37886cee56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8642611683848798"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test score\n",
    "X_test_title = val_df['title']\n",
    "nb_title_gs.score(X_test_title, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aaa8ac-6a32-45df-9025-99acfae53943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99200830-7692-49f8-ba14-6496882415bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a38963f-d4a6-4b23-b986-d736f25a71a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc46391-2cd3-4bac-894c-0042aab31130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb40b89-7f6a-4d51-a0ab-f91da71c54f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
