{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a94dd1c-96a4-47ad-b7d4-aec7a7c0066c",
   "metadata": {},
   "source": [
    "# Summary of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f87cb9-e8b9-4a8c-a923-320a6aa6a6c9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "49fc9aed-74cc-4352-a3ce-48e8d3280f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Import functions and preprocessors from last notebook\n",
    "from processing_functions import url_preprocessor, stem_processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26dfefe-2663-4b47-9db7-43494d23ba7e",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e2dfe1-c2fd-4428-b323-348c612943c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2325 entries, 107hfj5 to 10b33q8\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   title        2325 non-null   object \n",
      " 1   text         2325 non-null   object \n",
      " 2   utc          2325 non-null   float64\n",
      " 3   subreddit    2325 non-null   object \n",
      " 4   title_words  2325 non-null   int64  \n",
      " 5   text_words   2325 non-null   int64  \n",
      " 6   title_chars  2325 non-null   int64  \n",
      " 7   text_chars   2325 non-null   int64  \n",
      "dtypes: float64(1), int64(4), object(3)\n",
      "memory usage: 163.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv('../data/combined.csv', index_col='id')\n",
    "\n",
    "#Since Pandas converts empty strings to NaN's, we need to fill these in again\n",
    "df_all.fillna('', inplace=True)\n",
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0850072c-5362-4363-8f1f-c65b69d4fcb1",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "\n",
    "We reserve 20% of our data in the dataframe `test_df`.  The remaining 80% of the data will be used to train our models; we will store this data in the dataframe `df`.  We will not use the test data until the validation stage at the end of the modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d596cd5-0c71-43e6-84bb-fca872226f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Producers    930\n",
       "Composers    813\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, test_df = train_test_split(df_all,\n",
    "                               random_state=123,\n",
    "                               stratify=df_all['subreddit'])\n",
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e576b1a-0048-40ba-a7c3-d7b469c447b1",
   "metadata": {},
   "source": [
    "## Baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b977bd94-6a9b-4484-9146-75d234140cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Producers    0.533563\n",
       "Composers    0.466437\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0f5741-957e-4bda-927d-6b721f793817",
   "metadata": {},
   "source": [
    "So if we used a null model that just guessed the most common class (\"Producers\") in all cases, our accuracy score would be about 53.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d7567d-0101-41cf-8c70-a4ad1b695f77",
   "metadata": {},
   "source": [
    "## Words that strongly signal one subreddit over the other: An example\n",
    "\n",
    "Here, we pick up the idea mentioned at the end of the [last notebook](./03_EDA.ipynb).  After applying a `CountVectorizer` to the various titles of posts, we want to see which words are much *more common* among one subreddit or the other.  However, we need to take measures to avoid erroneously concluding that a word that appears only a very small number of times (say, only in the Producers data set) is a strong signal of one particular subreddit, when in reality it is simply a rare word but potentially equally likely to appear in either subreddit.  We can achieve this by setting the `min_df` hyperparameter of `CountVectorizer` large enough to avoid all incredibly rare words.  After doing so, for each remaining word that appears in the title of any post in either subreddit, we can construct the ratio\n",
    "\n",
    "`freq_ratio` = **(Frequency of word in Composers subreddit without `min_df`) / (Frequency of word in Producers subreddit without `min_df`)**.\n",
    "\n",
    "If this ratio is very large (and certainly if it is infinity), then seeing this word in the title of a post is a strong indicator that the post came from the Composers subreddit.  Conversely, if this ratio is very small (and certainly if it is zero), then seeing this word in the title of a post is a strong indicator that the post came from the Producers subreddit.\n",
    "\n",
    "To optimally incorporate this idea into our modeling, we'll want to perform a grid search for the best hyperparameters (such as `min_df`, whether to use titles only or also body texts, and what kind of preprocessing to do).  However, to understand this method before grid searching, we'll try one example using some \"reasonable\" values of the hyperparameters.  Specifically, for now we will:\n",
    "- Use only the titles of posts and look only at single words (no bigrams etc.).\n",
    "- Preprocess using the `url_preprocessor` (but not the `stem_processor`) from the last notebook.\n",
    "- Set a `min_df` value of .01, meaning that any word in consideration must appear in the title of at least 1% of posts (in the subreddit from which it came) in order to be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c920120c-b52c-4dd6-8bad-cbb0b8a1c8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title_words</th>\n",
       "      <th>text_words</th>\n",
       "      <th>title_chars</th>\n",
       "      <th>text_chars</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zoda66</th>\n",
       "      <td>First Composition, what do you think ?</td>\n",
       "      <td>Hi. I'm new into music, I tried to compose som...</td>\n",
       "      <td>1.671303e+09</td>\n",
       "      <td>Composers</td>\n",
       "      <td>8</td>\n",
       "      <td>68</td>\n",
       "      <td>38</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10axn2g</th>\n",
       "      <td>Tiki Taki - a piece in 15/8 time</td>\n",
       "      <td>I think this really swings, in a circular sort...</td>\n",
       "      <td>1.673625e+09</td>\n",
       "      <td>Composers</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>32</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title  \\\n",
       "id                                                \n",
       "zoda66   First Composition, what do you think ?   \n",
       "10axn2g        Tiki Taki - a piece in 15/8 time   \n",
       "\n",
       "                                                      text           utc  \\\n",
       "id                                                                         \n",
       "zoda66   Hi. I'm new into music, I tried to compose som...  1.671303e+09   \n",
       "10axn2g  I think this really swings, in a circular sort...  1.673625e+09   \n",
       "\n",
       "         subreddit  title_words  text_words  title_chars  text_chars  \n",
       "id                                                                    \n",
       "zoda66   Composers            8          68           38         437  \n",
       "10axn2g  Composers            8          56           32         460  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comps = df[df['subreddit']=='Composers']\n",
    "comps.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbc2725c-cbb3-49b7-85a9-ad8bcd31e260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title_words</th>\n",
       "      <th>text_words</th>\n",
       "      <th>title_chars</th>\n",
       "      <th>text_chars</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103osx2</th>\n",
       "      <td>halftime vs gross beat</td>\n",
       "      <td>is there any audible difference between using ...</td>\n",
       "      <td>1.672891e+09</td>\n",
       "      <td>Producers</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zznfx9</th>\n",
       "      <td>How do you achieve this synth sound?</td>\n",
       "      <td>In Redveil's song \"2daside\", what synth is use...</td>\n",
       "      <td>1.672468e+09</td>\n",
       "      <td>Producers</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "id                                              \n",
       "103osx2                halftime vs gross beat   \n",
       "zznfx9   How do you achieve this synth sound?   \n",
       "\n",
       "                                                      text           utc  \\\n",
       "id                                                                         \n",
       "103osx2  is there any audible difference between using ...  1.672891e+09   \n",
       "zznfx9   In Redveil's song \"2daside\", what synth is use...  1.672468e+09   \n",
       "\n",
       "         subreddit  title_words  text_words  title_chars  text_chars  \n",
       "id                                                                    \n",
       "103osx2  Producers            4          30           22         159  \n",
       "zznfx9   Producers            8          28           36         134  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prods = df[df['subreddit']=='Producers']\n",
    "prods.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "926f2a83-48aa-4690-890c-a39b04eab839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make dataframes of wordcounts in titles of posts\n",
    "\n",
    "#Transformer that vounts all words, regardless of frequency\n",
    "cv_all = CountVectorizer(stop_words = stopwords.words('english'),\n",
    "                     preprocessor= lambda x : url_preprocessor(x))\n",
    "\n",
    "#Transformer that counts only those words that appear in at least 1% of titles\n",
    "cv_top = CountVectorizer(stop_words = stopwords.words('english'),\n",
    "                     preprocessor= lambda x : url_preprocessor(x),\n",
    "                     min_df = .01)\n",
    "\n",
    "comps_top_words = cv_top.fit_transform(comps['title'])\n",
    "comps_top_words_df = pd.DataFrame(comps_top_words.todense(), columns=cv_top.get_feature_names_out(), index=comps.index)\n",
    "\n",
    "prods_top_words = cv_top.fit_transform(prods['title'])\n",
    "prods_top_words_df = pd.DataFrame(prods_top_words.todense(), columns=cv_top.get_feature_names_out(), index=prods.index)\n",
    "\n",
    "comps_all_words = cv_all.fit_transform(comps['title'])\n",
    "comps_all_words_df = pd.DataFrame(comps_all_words.todense(), columns=cv_all.get_feature_names_out(), index=comps.index)\n",
    "\n",
    "prods_all_words = cv_all.fit_transform(prods['title'])\n",
    "prods_all_words_df = pd.DataFrame(prods_all_words.todense(), columns=cv_all.get_feature_names_out(), index=prods.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "11d5a566-233d-40a1-8a6f-116227f13053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anyone', 'audio', 'band', 'best', 'chord', 'classical', 'compose',\n",
       "       'composer', 'composers', 'composing', 'composition', 'concerto',\n",
       "       'favorite', 'feedback', 'film', 'first', 'flute', 'free', 'fugue',\n",
       "       'get', 'good', 'guitar', 'help', 'inspired', 'instruments', 'know',\n",
       "       'like', 'little', 'looking', 'love', 'major', 'make', 'melody', 'minor',\n",
       "       'movement', 'musescore', 'music', 'need', 'new', 'notation', 'one',\n",
       "       'orchestra', 'orchestral', 'original', 'piano', 'piece', 'please',\n",
       "       'prelude', 'quartet', 'question', 'quintet', 'score', 'scores', 'short',\n",
       "       'software', 'solo', 'sonata', 'song', 'string', 'style', 'symphony',\n",
       "       'theme', 'think', 'time', 'two', 'use', 'video', 'violin', 'wind',\n",
       "       'work', 'would', 'write', 'writing', 'wrote'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What are the words that appear in at least 1% of titles of posts in \"Composers\"?\n",
    "comps_top_words_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25a0c77b-367d-4114-9afc-764ef3ab2252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ableton', 'advice', 'anyone', 'artists', 'audio', 'bass', 'beat',\n",
       "       'beats', 'beginner', 'best', 'create', 'daw', 'drum', 'drums', 'effect',\n",
       "       'find', 'first', 'fl', 'free', 'get', 'good', 'got', 'guitar',\n",
       "       'headphones', 'help', 'instruments', 'interface', 'key', 'keyboard',\n",
       "       'know', 'laptop', 'learn', 'like', 'live', 'logic', 'looking', 'made',\n",
       "       'make', 'making', 'mic', 'midi', 'mix', 'mixing', 'music', 'need',\n",
       "       'new', 'one', 'piano', 'please', 'plugin', 'plugins', 'pro', 'producer',\n",
       "       'producers', 'production', 'question', 'record', 'recording', 'sample',\n",
       "       'samples', 'software', 'someone', 'song', 'songs', 'sound', 'sounds',\n",
       "       'start', 'studio', 'synth', 'think', 'time', 'tips', 'track', 'trying',\n",
       "       'type', 'use', 'used', 'using', 'vocal', 'vocals', 'voice', 'vs', 'vst',\n",
       "       'want', 'way', 'work', 'worth', 'would'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What are the words that appear in at least 1% of titles of posts in \"Producers\"?\n",
    "prods_top_words_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcccca4-ffb5-450a-9972-9ae0e2b0cf56",
   "metadata": {},
   "source": [
    "Notice that these two sets of \"words that appear in at least 1% of titles\" have almost no overlap!  If we were, for each word in these lists, to simply define `freq_ratio` to be the ratio of its frequency in \"Composers\" posts to its frequency in \"Producers\" posts, the we would find that the `freq_ratio` of almost all of these words is either 0 or infinity.  This would give us no meaningful way to distinguish which of these \"strong indicators of one subreddit over the other\" is a *stronger* indicator than many of its peers.\n",
    "\n",
    "To fix this, we will calculate frequencies among the `comps_all_words_df` and `prods_all_words_df` - those dataframes that contain *all* the words that appear in any titles - rather than among merely the `comps_top_words_df` and `prods_top_words_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f3153873-76ec-4461-9415-2c0f69094313",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_check = set(list(comps_top_words_df.columns) + list(prods_top_words_df.columns))\n",
    "\n",
    "words = []\n",
    "freq_ratios = []\n",
    "\n",
    "for word in words_to_check:\n",
    "    #If the word only appears in the Producers data (not in Composers), set freq_ratio=0\n",
    "    if word not in comps_all_words_df.columns:\n",
    "        freq_ratio = 0\n",
    "        \n",
    "    #If the word only appears in the Composers data (not in Producers), set freq_ratio=infinity\n",
    "    elif word not in prods_all_words_df.columns:\n",
    "        freq_ratio = np.inf\n",
    "    \n",
    "    #If the word appears in both, take the ratio of frequencies\n",
    "    else:\n",
    "        comps_freq = comps_all_words_df.sum()[word]/len(comps)\n",
    "        prods_freq = prods_all_words_df.sum()[word]/len(prods)\n",
    "        freq_ratio = comps_freq / prods_freq\n",
    "    \n",
    "    words.append(word)\n",
    "    freq_ratios.append(freq_ratio)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "087ef0fa-08d2-45e8-8085-e809573d8a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_ratios_df = pd.DataFrame(freq_ratios, index=words)\n",
    "freq_ratios_df.columns = ['freq_ratio']\n",
    "len(freq_ratios_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef918919-081a-4019-8b34-8fa5c086d8d4",
   "metadata": {},
   "source": [
    "So 134 words appear in at least 1% of Producers titles *or* in at least 1% of Composers titles.  Among these words, which are the strongest indicators of each subreddit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a103d4-51d7-4506-b0ff-77f9a4b545bc",
   "metadata": {},
   "source": [
    "#### Words most strongly indicating \"Composers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "4c95b76a-bb24-4298-a7f1-49ea09e52455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>composer</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orchestra</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flute</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concerto</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prelude</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>piece</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minor</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theme</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fugue</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quintet</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>composition</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symphony</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonata</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>violin</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feedback</th>\n",
       "      <td>56.051661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>composing</th>\n",
       "      <td>33.173432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrote</th>\n",
       "      <td>27.453875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short</th>\n",
       "      <td>26.309963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quartet</th>\n",
       "      <td>22.878229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movement</th>\n",
       "      <td>21.734317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>string</th>\n",
       "      <td>16.014760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>musescore</th>\n",
       "      <td>14.870849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             freq_ratio\n",
       "composer            inf\n",
       "orchestra           inf\n",
       "flute               inf\n",
       "concerto            inf\n",
       "prelude             inf\n",
       "score               inf\n",
       "piece               inf\n",
       "minor               inf\n",
       "theme               inf\n",
       "fugue               inf\n",
       "quintet             inf\n",
       "composition         inf\n",
       "symphony            inf\n",
       "wind                inf\n",
       "sonata              inf\n",
       "violin              inf\n",
       "love                inf\n",
       "feedback      56.051661\n",
       "composing     33.173432\n",
       "wrote         27.453875\n",
       "short         26.309963\n",
       "quartet       22.878229\n",
       "movement      21.734317\n",
       "string        16.014760\n",
       "musescore     14.870849"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine the 25 words that have the highest frequency ratio,\n",
    "#i.e. the strongest indicators of \"Composers\" subreddit\n",
    "freq_ratios_df.sort_values('freq_ratio', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9491dda9-20d6-43fd-a69d-6490c3e96b33",
   "metadata": {},
   "source": [
    "#### Words most strongly indicating \"Producers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "90177632-d822-44fe-8e10-cfbfd6eae45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pro</th>\n",
       "      <td>0.067289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <td>0.063551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocal</th>\n",
       "      <td>0.060206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>synth</th>\n",
       "      <td>0.057196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beats</th>\n",
       "      <td>0.045756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>midi</th>\n",
       "      <td>0.038130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ableton</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daw</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logic</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixing</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interface</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mix</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>producer</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>production</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beat</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headphones</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocals</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plugins</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fl</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artists</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laptop</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            freq_ratio\n",
       "pro           0.067289\n",
       "sample        0.063551\n",
       "vocal         0.060206\n",
       "synth         0.057196\n",
       "beats         0.045756\n",
       "midi          0.038130\n",
       "ableton       0.000000\n",
       "mic           0.000000\n",
       "daw           0.000000\n",
       "logic         0.000000\n",
       "mixing        0.000000\n",
       "interface     0.000000\n",
       "mix           0.000000\n",
       "producer      0.000000\n",
       "production    0.000000\n",
       "got           0.000000\n",
       "beat          0.000000\n",
       "headphones    0.000000\n",
       "effect        0.000000\n",
       "vocals        0.000000\n",
       "plugins       0.000000\n",
       "fl            0.000000\n",
       "artists       0.000000\n",
       "samples       0.000000\n",
       "laptop        0.000000"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine the 25 words that have the lowest frequency ratio,\n",
    "#i.e. the strongest indicators of \"Producers\" subreddit\n",
    "freq_ratios_df.sort_values('freq_ratio', ascending=False).tail(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e90522a-d8a6-4d43-b82b-391091a9ba4f",
   "metadata": {},
   "source": [
    "Judging by my basic knowledge of music composition and production, the first \"top 25\" list *does* seem to contain mostly words that I would strongly associate with Composition over Production.  Similarly, the second list seems to contain mostly words that I would strongly associate with Production over Composition.  However, there are certainly some surprising exceptions, such as \"love\" and \"feedback\" in the first list and \"got\" in the second list.  This does not mean that these words are poor predictors, though - it's quite possible that e.g. the two subreddits have different cultures, making the word \"love\" much more common in one than the other.\n",
    "\n",
    "If a word in a post's title appears near the top (bottom) of the sorted list of 134 words - of which we saw the top and bottom 25 words - then that post is very likely to have come from the Composers (Producers) subreddit.  However, it is certainly not the case that all posts have one of these words in their titles.  For now, we can ask: of all the posts from either subreddit, how many contain a word in the top or bottom ~25% (top/bottom 34 words out of all 134) of the sorted list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a9718fdc-44cb-4294-abc1-756a31a41fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4991394148020654"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = freq_ratios_df.index\n",
    "#Top and bottom ~25.4% of the lists above\n",
    "tops = list(freq_ratios_df.sort_values('freq_ratio', ascending=False).head(34).index)\n",
    "bots = list(freq_ratios_df.sort_values('freq_ratio', ascending=False).tail(34).index)\n",
    "\n",
    "results=[]\n",
    "for ind in df.index:\n",
    "    flag=0\n",
    "    for word in tops + bots:\n",
    "        if word in df.loc[ind, 'title']:\n",
    "            flag=1\n",
    "            break\n",
    "    if flag==1:\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)\n",
    "\n",
    "#Compute the proportion of posts whose titles contain one of these \"top\" or \"bottom\" words\n",
    "res = pd.Series(results)\n",
    "res.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cb4ff4-e9cd-41a6-a50b-28c9701e0ca4",
   "metadata": {},
   "source": [
    "This means that just about half of all posts contain one of the words (\"top\" or \"bottom\" words) that strongly indicate one subreddit or another.  The other half of words do not give us such strong information about the subreddit from which they might have come.  A rough guess thus tells us that a model trained only on the titles of posts, and given access to the word counts only of the 134 words above, would probably classify about 75% of posts correctly.  This assumes the model will automatically be correct about any posts containing a \"top\" or \"bottom\" word in its title, and it will have to guess completely at random in all other cases; obviously this is just an approximation.\n",
    "\n",
    "To see how well such a basic model can perform, we will train a logistic regression model on nothing but the word counts of these 134 in the titles of posts.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cbd50385-9d48-4947-877d-db870d6bb346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anyone</th>\n",
       "      <th>audio</th>\n",
       "      <th>band</th>\n",
       "      <th>best</th>\n",
       "      <th>chord</th>\n",
       "      <th>classical</th>\n",
       "      <th>compose</th>\n",
       "      <th>composer</th>\n",
       "      <th>composers</th>\n",
       "      <th>composing</th>\n",
       "      <th>...</th>\n",
       "      <th>using</th>\n",
       "      <th>vocal</th>\n",
       "      <th>vocals</th>\n",
       "      <th>voice</th>\n",
       "      <th>vs</th>\n",
       "      <th>vst</th>\n",
       "      <th>want</th>\n",
       "      <th>way</th>\n",
       "      <th>worth</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zoda66</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Composers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10axn2g</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Composers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xwnm20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Composers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyd8hh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Composers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y03hjd</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Composers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10azzqv</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Producers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109519w</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Producers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zvii8w</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Producers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102f8yv</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Producers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107dyqs</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Producers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1743 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         anyone  audio  band  best  chord  classical  compose  composer  \\\n",
       "id                                                                        \n",
       "zoda66        0      0   0.0     0    0.0        0.0      0.0       0.0   \n",
       "10axn2g       0      0   0.0     0    0.0        0.0      0.0       0.0   \n",
       "xwnm20        0      0   0.0     0    0.0        0.0      0.0       0.0   \n",
       "zyd8hh        0      0   0.0     2    0.0        0.0      0.0       0.0   \n",
       "y03hjd        0      0   0.0     0    0.0        0.0      0.0       0.0   \n",
       "...         ...    ...   ...   ...    ...        ...      ...       ...   \n",
       "10azzqv       0      0   NaN     0    NaN        NaN      NaN       NaN   \n",
       "109519w       0      0   NaN     0    NaN        NaN      NaN       NaN   \n",
       "zvii8w        1      0   NaN     0    NaN        NaN      NaN       NaN   \n",
       "102f8yv       0      0   NaN     0    NaN        NaN      NaN       NaN   \n",
       "107dyqs       0      1   NaN     0    NaN        NaN      NaN       NaN   \n",
       "\n",
       "         composers  composing  ...  using  vocal  vocals  voice   vs  vst  \\\n",
       "id                             ...                                          \n",
       "zoda66         0.0        0.0  ...    NaN    NaN     NaN    NaN  NaN  NaN   \n",
       "10axn2g        0.0        0.0  ...    NaN    NaN     NaN    NaN  NaN  NaN   \n",
       "xwnm20         0.0        0.0  ...    NaN    NaN     NaN    NaN  NaN  NaN   \n",
       "zyd8hh         0.0        0.0  ...    NaN    NaN     NaN    NaN  NaN  NaN   \n",
       "y03hjd         0.0        1.0  ...    NaN    NaN     NaN    NaN  NaN  NaN   \n",
       "...            ...        ...  ...    ...    ...     ...    ...  ...  ...   \n",
       "10azzqv        NaN        NaN  ...    0.0    0.0     0.0    0.0  0.0  0.0   \n",
       "109519w        NaN        NaN  ...    0.0    0.0     0.0    0.0  0.0  0.0   \n",
       "zvii8w         NaN        NaN  ...    0.0    0.0     0.0    0.0  0.0  0.0   \n",
       "102f8yv        NaN        NaN  ...    0.0    0.0     0.0    0.0  0.0  0.0   \n",
       "107dyqs        NaN        NaN  ...    0.0    0.0     0.0    0.0  0.0  0.0   \n",
       "\n",
       "         want  way  worth  subreddit  \n",
       "id                                    \n",
       "zoda66    NaN  NaN    NaN  Composers  \n",
       "10axn2g   NaN  NaN    NaN  Composers  \n",
       "xwnm20    NaN  NaN    NaN  Composers  \n",
       "zyd8hh    NaN  NaN    NaN  Composers  \n",
       "y03hjd    NaN  NaN    NaN  Composers  \n",
       "...       ...  ...    ...        ...  \n",
       "10azzqv   0.0  0.0    0.0  Producers  \n",
       "109519w   0.0  0.0    0.0  Producers  \n",
       "zvii8w    0.0  0.0    0.0  Producers  \n",
       "102f8yv   0.0  0.0    0.0  Producers  \n",
       "107dyqs   0.0  0.0    0.0  Producers  \n",
       "\n",
       "[1743 rows x 135 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make a dataframe of just the 134 top words\n",
    "top_words_df = pd.concat([comps_top_words_df, prods_top_words_df])\n",
    "\n",
    "#Add back the classes to which each observation belongs\n",
    "top_words_df['subreddit'] = df['subreddit']\n",
    "\n",
    "top_words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de19abaa-f126-4387-9c0b-8e2d2c72a63c",
   "metadata": {},
   "source": [
    "As we can see, there are `NaN` values in this table corresponding to words that only appear in at least 1% of \"Composers\" titles but not at least 1% of \"Producers\" titles, and vice-versa.  This means that the proper word count for each of these `NaN` values is simply zero.  So we'll fill in these missing values before proceeding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dc5f4552-169c-4117-81b8-ecb679447597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anyone</th>\n",
       "      <th>audio</th>\n",
       "      <th>band</th>\n",
       "      <th>best</th>\n",
       "      <th>chord</th>\n",
       "      <th>classical</th>\n",
       "      <th>compose</th>\n",
       "      <th>composer</th>\n",
       "      <th>composers</th>\n",
       "      <th>composing</th>\n",
       "      <th>...</th>\n",
       "      <th>using</th>\n",
       "      <th>vocal</th>\n",
       "      <th>vocals</th>\n",
       "      <th>voice</th>\n",
       "      <th>vs</th>\n",
       "      <th>vst</th>\n",
       "      <th>want</th>\n",
       "      <th>way</th>\n",
       "      <th>worth</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zoda66</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Composers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10axn2g</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Composers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xwnm20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Composers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyd8hh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Composers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y03hjd</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Composers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         anyone  audio  band  best  chord  classical  compose  composer  \\\n",
       "id                                                                        \n",
       "zoda66        0      0   0.0     0    0.0        0.0      0.0       0.0   \n",
       "10axn2g       0      0   0.0     0    0.0        0.0      0.0       0.0   \n",
       "xwnm20        0      0   0.0     0    0.0        0.0      0.0       0.0   \n",
       "zyd8hh        0      0   0.0     2    0.0        0.0      0.0       0.0   \n",
       "y03hjd        0      0   0.0     0    0.0        0.0      0.0       0.0   \n",
       "\n",
       "         composers  composing  ...  using  vocal  vocals  voice   vs  vst  \\\n",
       "id                             ...                                          \n",
       "zoda66         0.0        0.0  ...    0.0    0.0     0.0    0.0  0.0  0.0   \n",
       "10axn2g        0.0        0.0  ...    0.0    0.0     0.0    0.0  0.0  0.0   \n",
       "xwnm20         0.0        0.0  ...    0.0    0.0     0.0    0.0  0.0  0.0   \n",
       "zyd8hh         0.0        0.0  ...    0.0    0.0     0.0    0.0  0.0  0.0   \n",
       "y03hjd         0.0        1.0  ...    0.0    0.0     0.0    0.0  0.0  0.0   \n",
       "\n",
       "         want  way  worth  subreddit  \n",
       "id                                    \n",
       "zoda66    0.0  0.0    0.0  Composers  \n",
       "10axn2g   0.0  0.0    0.0  Composers  \n",
       "xwnm20    0.0  0.0    0.0  Composers  \n",
       "zyd8hh    0.0  0.0    0.0  Composers  \n",
       "y03hjd    0.0  0.0    0.0  Composers  \n",
       "\n",
       "[5 rows x 135 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_df.fillna(0, inplace=True)\n",
    "top_words_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81028a8-e363-4659-8199-a6073c1d8b10",
   "metadata": {},
   "source": [
    "#### Gridsearch for basic logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "41caa784-905e-4d23-8ae6-160645ba3d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = top_words_df.drop(columns='subreddit')\n",
    "y = top_words_df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "04b8af8e-4a25-40ab-a06a-3dafb834c7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "86d2059b-be7a-4bcf-8b83-669c66fc55b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe_params = {\n",
    "    'lr__C' : np.logspace(-3,3,60)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b7754dc0-3cce-43cf-9b12-5233ac20008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid = GridSearchCV(lr_pipe, lr_pipe_params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d257fb5c-4794-448d-8564-55f5a0e07b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'lr__C': array([1.00000000e-03, 1.26384820e-03, 1.59731228e-03, 2.01876025e-03,\n",
       "       2.55140652e-03, 3.22459055e-03, 4.07539297e-03, 5.15067808e-03,\n",
       "       6.50967523e-03, 8.22724134e-03, 1.03979842e-02, 1.31414736e-02,\n",
       "       1.66088278e-02, 2.09910372e-02, 2.65294846...\n",
       "       4.58159767e+00, 5.79044398e+00, 7.31824222e+00, 9.24914728e+00,\n",
       "       1.16895182e+01, 1.47737765e+01, 1.86718109e+01, 2.35983347e+01,\n",
       "       2.98247129e+01, 3.76939098e+01, 4.76393801e+01, 6.02089449e+01,\n",
       "       7.60949669e+01, 9.61724871e+01, 1.21547425e+02, 1.53617495e+02,\n",
       "       1.94149195e+02, 2.45375111e+02, 3.10116893e+02, 3.91940677e+02,\n",
       "       4.95353521e+02, 6.26051657e+02, 7.91234262e+02, 1.00000000e+03])})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6f385468-f48b-4cc2-bd96-f4104a45cf17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8450894180416956"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd867e2-e3e7-45dc-8df1-55a2b43e49a2",
   "metadata": {},
   "source": [
    "Keep in mind that this score somewhat *overestimates* the performance of this model.  This is because, to properly use this method, we would need to *make an sklearn transformer* that automatically creates the `top_words_df` to feed into the model; this way the transformer can be separately fit to each of the folds in a gridsearch.  In our case we simply \"fit this transformer\" to *all* of our training data, rather than fitting it to only a random 80% of our training data at a time prior to using the other 20% to evaluate the results.\n",
    "\n",
    "We can make our `freq_ratio` transformer using sklearn's `FunctionTransformer` transformer.  `FunctionTransformer` simply takes a function and turns it into an sklearn transformer!  So we must only write the appropriate transformation *function*:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a448a12-9a34-4863-8731-c1a3a8f7c9e4",
   "metadata": {},
   "source": [
    "## Function to extract words with highest and lowest frequency ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "27af5951-d7f4-45bb-a24b-cb4d3ab0398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fr_transform(X, y, text_labels=None, cutoff_freq_ratio=0.0, cutoff_proportion=1.0, cvec_kwargs={}):\n",
    "    '''\n",
    "    NOTE: X and y MUST have a matching Pandas index!  Otherwise this function won't run properly.\n",
    "    \n",
    "    Inputs:\n",
    "    -A Pandas dataframe X of texts (possibly multiple columns of text in each row of X)\n",
    "    -A Pandas series y of exactly TWO classes to which each observation belongs\n",
    "    -A dictionary text_labels whose keys are the names of the various columns of text in X\n",
    "        and whose values are the names we'd like them to be called in the outputted \n",
    "        dataframe's columns.  For example, \n",
    "            {'title':'t', 'text':'b'}).\n",
    "        We count-vectorize the words in the columns separately; e.g. if the \"title\" is\n",
    "        'hello world' and the \"text\" is 'hello happy world' then the resulting columns\n",
    "        will look like t_hello, t_world, b_hello, b_happy, and b_world (using the example\n",
    "        dictionary above).\n",
    "        If no text_labels dictionary is passed, then the columns' separate texts will simply\n",
    "        be treated as parts of one big text: only one word count will be given for each word,\n",
    "        rather than a separate word count for each type (column) of text.\n",
    "    \n",
    "    Parameters:\n",
    "    -cutoff_freq_ratio (float, default 0): After finding the frequency ratio of each word,\n",
    "        keep that word in the outputted dataframe only if its frequency ratio (or the inverse\n",
    "        of its frequency ratio) is at least cutoff_freq_ratio.  For example, setting this to\n",
    "        10 means only those words that are at least 10 times as common in one class as compared\n",
    "        to the other will be kept in the resulting dataframe.\n",
    "    -cutoff_proportion (float, default 1): After finding all frequency ratios and sorting the\n",
    "        words by frequency ratio, keep only those words that appear in the top or bottom \n",
    "        cutoff_proportion proportion of this list.  For example, if cutoff_proportion=.25,\n",
    "        then only the top quarter and bottom quarter of the sorted list will be kept.\n",
    "    -cvec_kwargs: A dictionary of keyword arugments to be passed to CountVectorizer during\n",
    "        the processing.  For example, you can specify stop_words or min_df here, as well\n",
    "        as any custom preprocessing.\n",
    "        \n",
    "    Output:\n",
    "    Separately count-vectorizes the text(s) in each of the two classes.  For each word, calculates\n",
    "    the frequency of that word in each class.  Then takes the ratio of these frequencies for each word\n",
    "    (in each text type, if text_labels are passed) among the two classes.  Then returns a combined\n",
    "    dataframe of the count vectorizations, keeping only those words that meet the cutoff_freq_ratio\n",
    "    or cutoff_proportion (if given).\n",
    "    Here \"words\" can also mean n-grams, if an appropriate ngram_range is passed to cvec_kwargs.\n",
    "    '''\n",
    "    \n",
    "    #Raise errors if given bad inputs\n",
    "    if type(X) == pd.core.series.Series:\n",
    "        raise ValueError(\"X must be a Pandas dataframe, not a series\")\n",
    "    \n",
    "    if len(y.unique()) != 2:\n",
    "        raise ValueError(\"y variable does not have exactly 2 values so can't be used for classification\")\n",
    "        \n",
    "    if cutoff_freq_ratio > 0.0 and cutoff_proportion < .5:\n",
    "        raise ValueError(\"You can specify AT MOST ONE of cutoff_freq_ratio or cutoff_proportion\")\n",
    "        \n",
    "    if text_labels != None:\n",
    "        if set(text_labels.keys()) != set(X.columns):\n",
    "            raise ValueError(\"The keys of text_labels must match the names of the columns in X\")\n",
    "            \n",
    "    \n",
    "    #Make a column that concatenates (with spaces) the texts of all the text columns\n",
    "    #This will be useful in case text_labels is not given\n",
    "    X['%combined%']=X.apply((lambda x : ' '.join(x)), axis=1)\n",
    "    \n",
    "    #Split data by classes\n",
    "    classes = list(y.unique())\n",
    "    class0 = classes[0]\n",
    "    class1 = classes[1]\n",
    "    \n",
    "    #Make dataframes of X separately for each class\n",
    "    c0 = X[y==class0]\n",
    "    c1 = X[y==class1]\n",
    "    \n",
    "    \n",
    "    #Make vectorizers of all words (cv_all), or just words with a certain min_df, max_df, etc. (cv_top)\n",
    "    problem_kws = {'min_df', 'max_df', 'max_features'}\n",
    "    all_args_dict = {key:value for (key, value) in cvec_kwargs.items() if key not in problem_kws}\n",
    "    top_args_dict = cvec_kwargs\n",
    "    \n",
    "    cv_all = CountVectorizer(**all_args_dict)\n",
    "    cv_top = CountVectorizer(**top_args_dict)\n",
    "    \n",
    "    #Find word counts\n",
    "    \n",
    "    \n",
    "    #IF text_labels WERE NOT GIVEN:\n",
    "    #Use the '%combined%' column\n",
    "    if text_labels==None:\n",
    "\n",
    "        #Make dataframes\n",
    "        c0_top_words = cv_top.fit_transform(c0['%combined%'])\n",
    "        c0_top_words_df = pd.DataFrame(c0_top_words.todense(), columns=cv_top.get_feature_names_out(), index=c0.index)\n",
    "    \n",
    "        c1_top_words = cv_top.fit_transform(c1['%combined%'])\n",
    "        c1_top_words_df = pd.DataFrame(c1_top_words.todense(), columns=cv_top.get_feature_names_out(), index=c1.index)\n",
    "        \n",
    "        c0_all_words = cv_all.fit_transform(c0['%combined%'])\n",
    "        c0_all_words_df = pd.DataFrame(c0_all_words.todense(), columns=cv_all.get_feature_names_out(), index=c0.index)\n",
    "    \n",
    "        c1_all_words = cv_all.fit_transform(c1['%combined%'])\n",
    "        c1_all_words_df = pd.DataFrame(c1_all_words.todense(), columns=cv_all.get_feature_names_out(), index=c1.index)\n",
    "        \n",
    "        #Find frequencies\n",
    "        words_to_check = set(list(c0_top_words_df.columns) + list(c1_top_words_df.columns))\n",
    "\n",
    "        words = []\n",
    "        freq_ratios = []\n",
    "\n",
    "        #Loop over each word to find its frequency\n",
    "        for word in words_to_check:\n",
    "            #If the word only appears in the c1 data (not in c0), set freq_ratio=0\n",
    "            if word not in c0_all_words_df.columns:\n",
    "                freq_ratio = 0\n",
    "        \n",
    "            #If the word only appears in the c0 data (not in c1), set freq_ratio=infinity\n",
    "            elif word not in c1_all_words_df.columns:\n",
    "                freq_ratio = np.inf\n",
    "    \n",
    "            #If the word appears in both, take the ratio of frequencies\n",
    "            else:\n",
    "                c0_freq = c0_all_words_df.sum()[word]/len(c0)\n",
    "                c1_freq = c1_all_words_df.sum()[word]/len(c1)\n",
    "                freq_ratio = c0_freq / c1_freq\n",
    "    \n",
    "            words.append(word)\n",
    "            freq_ratios.append(freq_ratio)\n",
    "        \n",
    "        #Make frequency ratios into a dataframe indexed by the words\n",
    "        freq_ratios_df = pd.DataFrame(freq_ratios, index=words)\n",
    "        freq_ratios_df.columns = ['freq_ratio']\n",
    "        \n",
    "        \n",
    "\n",
    "        #Remove words that don't meet the specified cutoff\n",
    "        #1: cutoff_freq_ratio\n",
    "        if cutoff_freq_ratio > 0.0:\n",
    "            cutoff = cutoff_freq_ratio\n",
    "            inv_cutoff = 1/(cutoff_freq_ratio)\n",
    "            words_to_keep = []\n",
    "            for word in freq_ratios_df.index:\n",
    "                #If the frequency ratio is bigger than the cutoff or smaller than the inverse of the cutoff,\n",
    "                #then we'll keep this word.  Otherwise we won't\n",
    "                if (freq_ratios_df['freq_ratio'][word]>cutoff) or (freq_ratios_df['freq_ratio'][word]<inv_cutoff):\n",
    "                    words_to_keep.append(word)\n",
    "                    \n",
    "        #2: cutoff_proportion\n",
    "        elif cutoff_proportion < 0.5:\n",
    "            sorted_freq_ratios_df = freq_ratios_df.sort_values('freq_ratio', ascending=False)\n",
    "            n_tops = int(np.floor( len(sorted_freq_ratios_df)*cutoff_proportion ))\n",
    "            tops = sorted_freq_ratios_df.head(n_tops).index\n",
    "            bots = sorted_freq_ratios_df.tail(n_tops).index\n",
    "            words_to_keep = list(tops)+list(bots)\n",
    "        \n",
    "        #If no cutoffs were given, keep all the words that weren't eliminated by CountVectorizer already\n",
    "        else:\n",
    "            words_to_keep = list(freq_ratios_df.index)\n",
    "            \n",
    "\n",
    "        \n",
    "        #Make a dataframe of all the words not eliminated by CountVectorizer already\n",
    "        top_words_df = pd.concat([c0_top_words_df, c1_top_words_df])\n",
    "\n",
    "        #Keep only those words that meet the specified cutoff\n",
    "        top_words_df = top_words_df[words_to_keep]\n",
    "\n",
    "        #Missing values correspond to zero appearances of a word, so fill them with zeros\n",
    "        top_words_df.fillna(0, inplace=True)\n",
    "        \n",
    "        return top_words_df\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    #IF text_labels WERE GIVEN:\n",
    "    #vectorize each text column separately                   \n",
    "    else:\n",
    "        #Initialize a list of word count dataframes\n",
    "        counts_dfs = []\n",
    "        \n",
    "        for (col, cnum, kind) in itertools.product(X.columns, ['0', '1'], ['top','all']):\n",
    "            #Don't vectorize the combined column we made\n",
    "            if col=='%combined%':\n",
    "                continue\n",
    "            \n",
    "            #Get abbreviated column labels from text_labels\n",
    "            l = text_labels[col]\n",
    "            \n",
    "            #Make c0_top_title, c1_all_body, etc.\n",
    "            locals()[f\"c{cnum}_{kind}_{l}\"] = locals()[f\"cv_{kind}\"].fit_transform(locals()[f\"c{cnum}\"][col])\n",
    "            locals()[f\"c{cnum}_{kind}_{l}_df\"] = pd.DataFrame(locals()[f\"c{cnum}_{kind}_{l}\"].todense(),\n",
    "                                                              columns = locals()[f\"cv_{kind}\"].get_feature_names_out(),\n",
    "                                                              index = locals()[f\"c{cnum}\"].index\n",
    "                                                             )\n",
    "            #Add the t_ or b_ to the names of the columns (words)\n",
    "            locals()[f\"c{cnum}_{kind}_{l}_df\"] = locals()[f\"c{cnum}_{kind}_{l}_df\"].add_prefix(f\"{l}_\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "8bb93241-c1ad-4184-a236-1b5d534e7eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>easiest</th>\n",
       "      <th>musical</th>\n",
       "      <th>five</th>\n",
       "      <th>extract</th>\n",
       "      <th>instruments</th>\n",
       "      <th>toccata</th>\n",
       "      <th>portal</th>\n",
       "      <th>installing</th>\n",
       "      <th>hire</th>\n",
       "      <th>aux</th>\n",
       "      <th>...</th>\n",
       "      <th>copy</th>\n",
       "      <th>apogee</th>\n",
       "      <th>ni</th>\n",
       "      <th>sl</th>\n",
       "      <th>etude</th>\n",
       "      <th>scordatura</th>\n",
       "      <th>today</th>\n",
       "      <th>remake</th>\n",
       "      <th>trusted</th>\n",
       "      <th>first</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103osx2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zznfx9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104099x</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zpzpr1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109kf6x</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlvs5s</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yim1o9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y2gyh6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zka7hl</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xoulev</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1743 rows × 3386 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         easiest  musical  five  extract  instruments  toccata  portal  \\\n",
       "id                                                                       \n",
       "103osx2      0.0      0.0   0.0      0.0            0      0.0     0.0   \n",
       "zznfx9       0.0      0.0   0.0      0.0            0      0.0     0.0   \n",
       "104099x      0.0      0.0   0.0      0.0            0      0.0     0.0   \n",
       "zpzpr1       0.0      0.0   0.0      0.0            0      0.0     0.0   \n",
       "109kf6x      0.0      0.0   0.0      0.0            0      0.0     0.0   \n",
       "...          ...      ...   ...      ...          ...      ...     ...   \n",
       "xlvs5s       0.0      0.0   0.0      0.0            0      0.0     0.0   \n",
       "yim1o9       0.0      0.0   0.0      0.0            0      0.0     0.0   \n",
       "y2gyh6       0.0      0.0   0.0      0.0            0      0.0     0.0   \n",
       "zka7hl       0.0      0.0   0.0      0.0            0      0.0     0.0   \n",
       "xoulev       0.0      0.0   0.0      0.0            0      0.0     0.0   \n",
       "\n",
       "         installing  hire  aux  ...  copy  apogee   ni   sl  etude  \\\n",
       "id                              ...                                  \n",
       "103osx2         0.0   0.0  0.0  ...   0.0     0.0  0.0  0.0    0.0   \n",
       "zznfx9          0.0   0.0  0.0  ...   0.0     0.0  0.0  0.0    0.0   \n",
       "104099x         0.0   0.0  0.0  ...   0.0     0.0  0.0  0.0    0.0   \n",
       "zpzpr1          0.0   0.0  0.0  ...   0.0     0.0  0.0  0.0    0.0   \n",
       "109kf6x         0.0   0.0  0.0  ...   0.0     0.0  0.0  0.0    0.0   \n",
       "...             ...   ...  ...  ...   ...     ...  ...  ...    ...   \n",
       "xlvs5s          0.0   0.0  0.0  ...   0.0     0.0  0.0  0.0    0.0   \n",
       "yim1o9          0.0   0.0  0.0  ...   0.0     0.0  0.0  0.0    0.0   \n",
       "y2gyh6          0.0   0.0  0.0  ...   0.0     0.0  0.0  0.0    0.0   \n",
       "zka7hl          0.0   0.0  0.0  ...   0.0     0.0  0.0  0.0    0.0   \n",
       "xoulev          0.0   0.0  0.0  ...   0.0     0.0  0.0  0.0    0.0   \n",
       "\n",
       "         scordatura  today  remake  trusted  first  \n",
       "id                                                  \n",
       "103osx2         0.0    0.0     0.0      0.0      0  \n",
       "zznfx9          0.0    0.0     0.0      0.0      0  \n",
       "104099x         0.0    0.0     0.0      0.0      0  \n",
       "zpzpr1          0.0    0.0     0.0      0.0      0  \n",
       "109kf6x         0.0    0.0     0.0      0.0      0  \n",
       "...             ...    ...     ...      ...    ...  \n",
       "xlvs5s          0.0    0.0     0.0      0.0      0  \n",
       "yim1o9          0.0    0.0     0.0      0.0      0  \n",
       "y2gyh6          0.0    0.0     0.0      0.0      0  \n",
       "zka7hl          0.0    0.0     0.0      0.0      0  \n",
       "xoulev          0.0    0.0     0.0      0.0      5  \n",
       "\n",
       "[1743 rows x 3386 columns]"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_transformer = FunctionTransformer(lambda args : fr_transform(*args) )\n",
    "my_transformer.fit_transform([X,y])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce11676-8fd1-4654-94b5-e3287834e916",
   "metadata": {},
   "source": [
    "## Testing the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d210cb-0ffa-48ee-8213-7e0b87c63a8e",
   "metadata": {},
   "source": [
    "Here we'll try to replicate the process of dropping those words that appear in the titles of fewer than 1% of \"Composers\" posts and \"Producers\" posts - but this time, using the function we wrote!  Note that this exercise doesn't actually employ the frequency ratios calculated by the function; in order to use these, we have to pass a `cutoff_freq_ratio` or a `cutoff_proportion` to the function.  In any case, we found that there were 134 words that were in at least 1% of posts' titles, so if things are working correctly then we should have 134 columns in the resulting dataframe below.  We should also have 1743 rows, corresponding to the 1743 observations in our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "d1970c17-c69f-4925-8893-a65142c12519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replicating our previous work, but this time using the function\n",
    "X = df[['title']]\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "60f47a4f-0e94-429a-8c28-bef48d41de7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1743, 134)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruments</th>\n",
       "      <th>know</th>\n",
       "      <th>producers</th>\n",
       "      <th>synth</th>\n",
       "      <th>love</th>\n",
       "      <th>violin</th>\n",
       "      <th>daw</th>\n",
       "      <th>mic</th>\n",
       "      <th>best</th>\n",
       "      <th>music</th>\n",
       "      <th>...</th>\n",
       "      <th>composition</th>\n",
       "      <th>think</th>\n",
       "      <th>logic</th>\n",
       "      <th>sonata</th>\n",
       "      <th>musescore</th>\n",
       "      <th>drum</th>\n",
       "      <th>create</th>\n",
       "      <th>free</th>\n",
       "      <th>string</th>\n",
       "      <th>first</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103osx2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zznfx9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         instruments  know  producers  synth  love  violin  daw  mic  best  \\\n",
       "id                                                                           \n",
       "103osx2            0     0        0.0    0.0   0.0     0.0  0.0  0.0     0   \n",
       "zznfx9             0     0        0.0    1.0   0.0     0.0  0.0  0.0     0   \n",
       "\n",
       "         music  ...  composition  think  logic  sonata  musescore  drum  \\\n",
       "id              ...                                                       \n",
       "103osx2      0  ...          0.0      0    0.0     0.0        0.0   0.0   \n",
       "zznfx9       0  ...          0.0      0    0.0     0.0        0.0   0.0   \n",
       "\n",
       "         create  free  string  first  \n",
       "id                                    \n",
       "103osx2     0.0     0     0.0      0  \n",
       "zznfx9      0.0     0     0.0      0  \n",
       "\n",
       "[2 rows x 134 columns]"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1 = fr_transform(X, y,\n",
    "                     cvec_kwargs={'stop_words' : stopwords.words('english'),\n",
    "                     'preprocessor' : (lambda x : url_preprocessor(x)),\n",
    "                     'min_df' : .01\n",
    "             })\n",
    "#Function returns result dataframe as first output and also spits back y as second output\n",
    "res1 = result1\n",
    "\n",
    "print(res1.shape)\n",
    "res1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a706f16-642f-4a1d-afad-c7dd48fefe8b",
   "metadata": {},
   "source": [
    "### Using `cutoff_proportion` to replicate the above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9cecb9-1313-4ed5-8028-32bdb4afc781",
   "metadata": {},
   "source": [
    "Above, we looked at the top 25 and bottom 25 words from our (134-word) dataframe that was sorted by frequency ratio.  Since `25 == floor(.187*134)`, we should get back these same 50 words by setting a `cutoff_proportion` equal to .187 in our function.  So if things are running correctly, then the resulting dataframe below should have the same 50 words we saw before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f3773de2-03f8-4e2f-9e2f-56a2c73de712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1743, 50)\n",
      "['mix', 'laptop', 'mixing', 'producer', 'vocals', 'got', 'artists', 'plugins', 'headphones', 'logic', 'ableton', 'production', 'effect', 'mic', 'daw', 'samples', 'beat', 'interface', 'fl', 'midi', 'beats', 'synth', 'vocal', 'sample', 'producers', 'musescore', 'string', 'movement', 'quartet', 'short', 'wrote', 'composing', 'feedback', 'concerto', 'orchestra', 'piece', 'love', 'violin', 'composer', 'quintet', 'sonata', 'composition', 'symphony', 'fugue', 'score', 'wind', 'theme', 'prelude', 'minor', 'flute']\n"
     ]
    }
   ],
   "source": [
    "result2 = fr_transform(X, y,\n",
    "                       cutoff_proportion = .187,\n",
    "                     cvec_kwargs={'stop_words' : stopwords.words('english'),\n",
    "                     'preprocessor' : (lambda x : url_preprocessor(x)),\n",
    "                     'min_df' : .01\n",
    "             })\n",
    "\n",
    "#This should have 68 columns if things are working correctly.\n",
    "print(result2.shape)\n",
    "\n",
    "print(list(result2.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b81696a-cc38-47d0-a771-86bbb56703b2",
   "metadata": {},
   "source": [
    "### Using `cutoff_freq_ratio` to find the strongest bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e0d340-021d-4f1f-975a-9c8dc2aded6c",
   "metadata": {},
   "source": [
    "This time, let's use the function to produce only those bigrams that are at least 10 times as common among \"Composers\" titles as among \"Producers\" titles, or at least 10 times as common among \"Producers\" titles as among \"Composers\" titles.  We'll leave it to the reader to guess which bigrams tend to come from which subreddit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "9ef11a04-9bcb-49e7-9bcf-05d2a0f61766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1743, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>looking feedback</th>\n",
       "      <th>music production</th>\n",
       "      <th>fl studio</th>\n",
       "      <th>string quartet</th>\n",
       "      <th>original composition</th>\n",
       "      <th>audio interface</th>\n",
       "      <th>piano piece</th>\n",
       "      <th>love feedback</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103osx2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zznfx9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         looking feedback  music production  fl studio  string quartet  \\\n",
       "id                                                                       \n",
       "103osx2               0.0               0.0        0.0             0.0   \n",
       "zznfx9                0.0               0.0        0.0             0.0   \n",
       "\n",
       "         original composition  audio interface  piano piece  love feedback  \n",
       "id                                                                          \n",
       "103osx2                   0.0              0.0          0.0            0.0  \n",
       "zznfx9                    0.0              0.0          0.0            0.0  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3 = fr_transform(X, y,\n",
    "                       cutoff_freq_ratio = 10,\n",
    "                     cvec_kwargs={'stop_words' : stopwords.words('english'),\n",
    "                     'preprocessor' : (lambda x : url_preprocessor(x)),\n",
    "                     'min_df' : .01,\n",
    "                     'ngram_range' : (2,2)\n",
    "             })\n",
    "\n",
    "print(result3.shape)\n",
    "result3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "0f2adcba-19be-4e36-b99f-21e88722eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class FunctionTransformer2(TransformerMixin, BaseEstimator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        func=None,\n",
    "        kw_args=None,\n",
    "        ):\n",
    "        self.func = func\n",
    "        self.kw_args = kw_args\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    def transform(self, X, y):\n",
    "        return (self.func(X, y), y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba1585-0406-499a-ac94-6cb603f714ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67924c3-b9a6-464c-8b91-2668252978c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43c578e1-52d2-4f98-9e5c-c0e2781de863",
   "metadata": {},
   "source": [
    "## `fr_transform` in a pipeline: Using `FunctionTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "805456d5-0140-4f72-a871-e76157d9d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('fr', FunctionTransformer2(lambda args: fr_transform(*args)) ),\n",
    "    ('logit', LogisticRegression())\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "5c95ede4-1a7c-4512-b104-f328eb22cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "51221cb6-2ead-4775-9e03-6cb50c1ea72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'fr__kw_args':[{\n",
    "        'cutoff_freq_ratio':0.0,\n",
    "        'cvec_kwargs':{\n",
    "            'stop_words' : stopwords.words('english'),\n",
    "            'preprocessor' : (lambda x : url_preprocessor(x)),\n",
    "            'min_df' : .01\n",
    "        }\n",
    "    }],\n",
    "    \n",
    "    'logit__C': np.logspace(-3,3,60)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "548c4eed-e643-4440-9e8a-a986f0d57614",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipe, pipe_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "6677ed73-d028-46c8-bd5e-0597fbe145bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "transform() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5v/3x2_29n942n4k09n89jp09m80000gn/T/ipykernel_33494/1139796245.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \"\"\"\n\u001b[1;32m    389\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    349\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: transform() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a486612-4f68-48a2-bf56-92cbeca59be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b78c273-b2fe-463e-a240-0f8f7f2bca0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166739ac-c51a-4217-9407-e33a23a96921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714eb287-409e-47e0-b17e-358c73f13fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c243535-8fed-4ba9-991c-78d0e7e81264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
