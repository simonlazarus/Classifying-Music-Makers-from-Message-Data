{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a94dd1c-96a4-47ad-b7d4-aec7a7c0066c",
   "metadata": {},
   "source": [
    "# Summary of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f87cb9-e8b9-4a8c-a923-320a6aa6a6c9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "49fc9aed-74cc-4352-a3ce-48e8d3280f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Import functions and preprocessors from previous notebook\n",
    "from processing_functions import url_preprocessor, stem_processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26dfefe-2663-4b47-9db7-43494d23ba7e",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e2dfe1-c2fd-4428-b323-348c612943c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2325 entries, 107hfj5 to 10b33q8\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   title        2325 non-null   object \n",
      " 1   text         2325 non-null   object \n",
      " 2   utc          2325 non-null   float64\n",
      " 3   subreddit    2325 non-null   object \n",
      " 4   title_words  2325 non-null   int64  \n",
      " 5   text_words   2325 non-null   int64  \n",
      " 6   title_chars  2325 non-null   int64  \n",
      " 7   text_chars   2325 non-null   int64  \n",
      "dtypes: float64(1), int64(4), object(3)\n",
      "memory usage: 163.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv('../data/combined.csv', index_col='id')\n",
    "\n",
    "#Since Pandas converts empty strings to NaN's, we need to fill these in again\n",
    "df_all.fillna('', inplace=True)\n",
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0850072c-5362-4363-8f1f-c65b69d4fcb1",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "\n",
    "We reserve 20% of our data in the dataframe `val_df`.  The remaining 80% of the data will be used to train our models; we will store this data in the dataframe `df`.  We will not use the `val_df` data until the validation stage at the end of the modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d596cd5-0c71-43e6-84bb-fca872226f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Producers    930\n",
       "Composers    813\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, val_df = train_test_split(df_all,\n",
    "                               random_state=123,\n",
    "                               stratify=df_all['subreddit'])\n",
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e576b1a-0048-40ba-a7c3-d7b469c447b1",
   "metadata": {},
   "source": [
    "## Baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b977bd94-6a9b-4484-9146-75d234140cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Producers    0.533563\n",
       "Composers    0.466437\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0f5741-957e-4bda-927d-6b721f793817",
   "metadata": {},
   "source": [
    "So if we used a null model that just guessed the most common class (\"Producers\") in all cases, our accuracy score would be about 53.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d7567d-0101-41cf-8c70-a4ad1b695f77",
   "metadata": {},
   "source": [
    "## Words that strongly signal one subreddit over the other: An example\n",
    "\n",
    "Here, we pick up the idea mentioned at the end of the [last notebook](./03_EDA.ipynb).  After applying a `CountVectorizer` to the various titles of posts, we want to see which words are much *more common* among one subreddit or the other.  However, we need to take measures to avoid erroneously concluding that a word that appears only a very small number of times (say, only in the Producers data set) is a strong signal of one particular subreddit, when in reality it is simply a rare word but potentially equally likely to appear in either subreddit.  We can achieve this by setting the `min_df` hyperparameter of `CountVectorizer` large enough to avoid all incredibly rare words.  After doing so, for each remaining word that appears in the title of any post in either subreddit, we can construct the ratio\n",
    "\n",
    "`freq_ratio` = **(Frequency of word in Composers subreddit without `min_df`) / (Frequency of word in Producers subreddit without `min_df`)**.\n",
    "\n",
    "If this ratio is very large (and certainly if it is infinity), then seeing this word in the title of a post is a strong indicator that the post came from the Composers subreddit.  Conversely, if this ratio is very small (and certainly if it is zero), then seeing this word in the title of a post is a strong indicator that the post came from the Producers subreddit.\n",
    "\n",
    "To optimally incorporate this idea into our modeling, we'll want to perform a grid search for the best hyperparameters (such as `min_df`, whether to use titles only or also body texts, and what kind of preprocessing to do).  However, to understand this method before grid searching, we'll try one example using some \"reasonable\" values of the hyperparameters.  Specifically, for now we will:\n",
    "- Use only the titles of posts and look only at single words (no bigrams etc.).\n",
    "- Preprocess using the `url_preprocessor` (but not the `stem_processor`) from the last notebook.\n",
    "- Set a `min_df` value of .01, meaning that any word in consideration must appear in the title of at least 1% of posts (in the subreddit from which it came) in order to be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c920120c-b52c-4dd6-8bad-cbb0b8a1c8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title_words</th>\n",
       "      <th>text_words</th>\n",
       "      <th>title_chars</th>\n",
       "      <th>text_chars</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zoda66</th>\n",
       "      <td>First Composition, what do you think ?</td>\n",
       "      <td>Hi. I'm new into music, I tried to compose som...</td>\n",
       "      <td>1.671303e+09</td>\n",
       "      <td>Composers</td>\n",
       "      <td>8</td>\n",
       "      <td>68</td>\n",
       "      <td>38</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10axn2g</th>\n",
       "      <td>Tiki Taki - a piece in 15/8 time</td>\n",
       "      <td>I think this really swings, in a circular sort...</td>\n",
       "      <td>1.673625e+09</td>\n",
       "      <td>Composers</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>32</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title  \\\n",
       "id                                                \n",
       "zoda66   First Composition, what do you think ?   \n",
       "10axn2g        Tiki Taki - a piece in 15/8 time   \n",
       "\n",
       "                                                      text           utc  \\\n",
       "id                                                                         \n",
       "zoda66   Hi. I'm new into music, I tried to compose som...  1.671303e+09   \n",
       "10axn2g  I think this really swings, in a circular sort...  1.673625e+09   \n",
       "\n",
       "         subreddit  title_words  text_words  title_chars  text_chars  \n",
       "id                                                                    \n",
       "zoda66   Composers            8          68           38         437  \n",
       "10axn2g  Composers            8          56           32         460  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comps = df[df['subreddit']=='Composers']\n",
    "comps.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbc2725c-cbb3-49b7-85a9-ad8bcd31e260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title_words</th>\n",
       "      <th>text_words</th>\n",
       "      <th>title_chars</th>\n",
       "      <th>text_chars</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103osx2</th>\n",
       "      <td>halftime vs gross beat</td>\n",
       "      <td>is there any audible difference between using ...</td>\n",
       "      <td>1.672891e+09</td>\n",
       "      <td>Producers</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zznfx9</th>\n",
       "      <td>How do you achieve this synth sound?</td>\n",
       "      <td>In Redveil's song \"2daside\", what synth is use...</td>\n",
       "      <td>1.672468e+09</td>\n",
       "      <td>Producers</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "id                                              \n",
       "103osx2                halftime vs gross beat   \n",
       "zznfx9   How do you achieve this synth sound?   \n",
       "\n",
       "                                                      text           utc  \\\n",
       "id                                                                         \n",
       "103osx2  is there any audible difference between using ...  1.672891e+09   \n",
       "zznfx9   In Redveil's song \"2daside\", what synth is use...  1.672468e+09   \n",
       "\n",
       "         subreddit  title_words  text_words  title_chars  text_chars  \n",
       "id                                                                    \n",
       "103osx2  Producers            4          30           22         159  \n",
       "zznfx9   Producers            8          28           36         134  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prods = df[df['subreddit']=='Producers']\n",
    "prods.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "926f2a83-48aa-4690-890c-a39b04eab839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make dataframes of wordcounts in titles of posts\n",
    "\n",
    "#Transformer that vounts all words, regardless of frequency\n",
    "cv_all = CountVectorizer(stop_words = stopwords.words('english'),\n",
    "                     preprocessor= lambda x : url_preprocessor(x))\n",
    "\n",
    "#Transformer that counts only those words that appear in at least 1% of titles\n",
    "cv_top = CountVectorizer(stop_words = stopwords.words('english'),\n",
    "                     preprocessor= lambda x : url_preprocessor(x),\n",
    "                     min_df = .01)\n",
    "\n",
    "comps_top_words = cv_top.fit_transform(comps['title'])\n",
    "comps_top_words_df = pd.DataFrame(comps_top_words.todense(), columns=cv_top.get_feature_names_out(), index=comps.index)\n",
    "\n",
    "prods_top_words = cv_top.fit_transform(prods['title'])\n",
    "prods_top_words_df = pd.DataFrame(prods_top_words.todense(), columns=cv_top.get_feature_names_out(), index=prods.index)\n",
    "\n",
    "comps_all_words = cv_all.fit_transform(comps['title'])\n",
    "comps_all_words_df = pd.DataFrame(comps_all_words.todense(), columns=cv_all.get_feature_names_out(), index=comps.index)\n",
    "\n",
    "prods_all_words = cv_all.fit_transform(prods['title'])\n",
    "prods_all_words_df = pd.DataFrame(prods_all_words.todense(), columns=cv_all.get_feature_names_out(), index=prods.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11d5a566-233d-40a1-8a6f-116227f13053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anyone', 'audio', 'band', 'best', 'chord', 'classical', 'compose',\n",
       "       'composer', 'composers', 'composing', 'composition', 'concerto',\n",
       "       'favorite', 'feedback', 'film', 'first', 'flute', 'free', 'fugue',\n",
       "       'get', 'good', 'guitar', 'help', 'inspired', 'instruments', 'know',\n",
       "       'like', 'little', 'looking', 'love', 'major', 'make', 'melody', 'minor',\n",
       "       'movement', 'musescore', 'music', 'need', 'new', 'notation', 'one',\n",
       "       'orchestra', 'orchestral', 'original', 'piano', 'piece', 'please',\n",
       "       'prelude', 'quartet', 'question', 'quintet', 'score', 'scores', 'short',\n",
       "       'software', 'solo', 'sonata', 'song', 'string', 'style', 'symphony',\n",
       "       'theme', 'think', 'time', 'two', 'use', 'video', 'violin', 'wind',\n",
       "       'work', 'would', 'write', 'writing', 'wrote'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What are the words that appear in at least 1% of titles of posts in \"Composers\"?\n",
    "comps_top_words_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25a0c77b-367d-4114-9afc-764ef3ab2252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ableton', 'advice', 'anyone', 'artists', 'audio', 'bass', 'beat',\n",
       "       'beats', 'beginner', 'best', 'create', 'daw', 'drum', 'drums', 'effect',\n",
       "       'find', 'first', 'fl', 'free', 'get', 'good', 'got', 'guitar',\n",
       "       'headphones', 'help', 'instruments', 'interface', 'key', 'keyboard',\n",
       "       'know', 'laptop', 'learn', 'like', 'live', 'logic', 'looking', 'made',\n",
       "       'make', 'making', 'mic', 'midi', 'mix', 'mixing', 'music', 'need',\n",
       "       'new', 'one', 'piano', 'please', 'plugin', 'plugins', 'pro', 'producer',\n",
       "       'producers', 'production', 'question', 'record', 'recording', 'sample',\n",
       "       'samples', 'software', 'someone', 'song', 'songs', 'sound', 'sounds',\n",
       "       'start', 'studio', 'synth', 'think', 'time', 'tips', 'track', 'trying',\n",
       "       'type', 'use', 'used', 'using', 'vocal', 'vocals', 'voice', 'vs', 'vst',\n",
       "       'want', 'way', 'work', 'worth', 'would'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What are the words that appear in at least 1% of titles of posts in \"Producers\"?\n",
    "prods_top_words_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcccca4-ffb5-450a-9972-9ae0e2b0cf56",
   "metadata": {},
   "source": [
    "Notice that these two sets of \"words that appear in at least 1% of titles\" have almost no overlap!  If we were, for each word in these lists, to simply define `freq_ratio` to be the ratio of its frequency in \"Composers\" posts to its frequency in \"Producers\" posts, the we would find that the `freq_ratio` of almost all of these words is either 0 or infinity.  This would give us no meaningful way to distinguish which of these \"strong indicators of one subreddit over the other\" is a *stronger* indicator than many of its peers.\n",
    "\n",
    "To fix this, we will calculate frequencies among the `comps_all_words_df` and `prods_all_words_df` - those dataframes that contain *all* the words that appear in any titles - rather than among merely the `comps_top_words_df` and `prods_top_words_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3153873-76ec-4461-9415-2c0f69094313",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_check = set(list(comps_top_words_df.columns) + list(prods_top_words_df.columns))\n",
    "\n",
    "words = []\n",
    "freq_ratios = []\n",
    "\n",
    "for word in words_to_check:\n",
    "    #If the word only appears in the Producers data (not in Composers), set freq_ratio=0\n",
    "    if word not in comps_all_words_df.columns:\n",
    "        freq_ratio = 0\n",
    "        \n",
    "    #If the word only appears in the Composers data (not in Producers), set freq_ratio=infinity\n",
    "    elif word not in prods_all_words_df.columns:\n",
    "        freq_ratio = np.inf\n",
    "    \n",
    "    #If the word appears in both, take the ratio of frequencies\n",
    "    else:\n",
    "        comps_freq = comps_all_words_df.sum()[word]/len(comps)\n",
    "        prods_freq = prods_all_words_df.sum()[word]/len(prods)\n",
    "        freq_ratio = comps_freq / prods_freq\n",
    "    \n",
    "    words.append(word)\n",
    "    freq_ratios.append(freq_ratio)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "087ef0fa-08d2-45e8-8085-e809573d8a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_ratios_df = pd.DataFrame(freq_ratios, index=words)\n",
    "freq_ratios_df.columns = ['freq_ratio']\n",
    "len(freq_ratios_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef918919-081a-4019-8b34-8fa5c086d8d4",
   "metadata": {},
   "source": [
    "So 134 words appear in at least 1% of Producers titles *or* in at least 1% of Composers titles.  Among these words, which are the strongest indicators of each subreddit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a103d4-51d7-4506-b0ff-77f9a4b545bc",
   "metadata": {},
   "source": [
    "#### Words most strongly indicating \"Composers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c95b76a-bb24-4298-a7f1-49ea09e52455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fugue</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonata</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theme</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>piece</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prelude</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>composer</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>violin</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symphony</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flute</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>composition</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orchestra</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concerto</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minor</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quintet</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feedback</th>\n",
       "      <td>56.051661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>composing</th>\n",
       "      <td>33.173432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrote</th>\n",
       "      <td>27.453875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short</th>\n",
       "      <td>26.309963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quartet</th>\n",
       "      <td>22.878229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movement</th>\n",
       "      <td>21.734317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>string</th>\n",
       "      <td>16.014760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>musescore</th>\n",
       "      <td>14.870849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             freq_ratio\n",
       "fugue               inf\n",
       "sonata              inf\n",
       "love                inf\n",
       "theme               inf\n",
       "piece               inf\n",
       "score               inf\n",
       "wind                inf\n",
       "prelude             inf\n",
       "composer            inf\n",
       "violin              inf\n",
       "symphony            inf\n",
       "flute               inf\n",
       "composition         inf\n",
       "orchestra           inf\n",
       "concerto            inf\n",
       "minor               inf\n",
       "quintet             inf\n",
       "feedback      56.051661\n",
       "composing     33.173432\n",
       "wrote         27.453875\n",
       "short         26.309963\n",
       "quartet       22.878229\n",
       "movement      21.734317\n",
       "string        16.014760\n",
       "musescore     14.870849"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine the 25 words that have the highest frequency ratio,\n",
    "#i.e. the strongest indicators of \"Composers\" subreddit\n",
    "freq_ratios_df.sort_values('freq_ratio', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9491dda9-20d6-43fd-a69d-6490c3e96b33",
   "metadata": {},
   "source": [
    "#### Words most strongly indicating \"Producers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90177632-d822-44fe-8e10-cfbfd6eae45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pro</th>\n",
       "      <td>0.067289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <td>0.063551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocal</th>\n",
       "      <td>0.060206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>synth</th>\n",
       "      <td>0.057196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beats</th>\n",
       "      <td>0.045756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>midi</th>\n",
       "      <td>0.038130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mic</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daw</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixing</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headphones</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocals</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logic</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>production</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laptop</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fl</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interface</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ableton</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beat</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>producer</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mix</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plugins</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artists</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            freq_ratio\n",
       "pro           0.067289\n",
       "sample        0.063551\n",
       "vocal         0.060206\n",
       "synth         0.057196\n",
       "beats         0.045756\n",
       "midi          0.038130\n",
       "mic           0.000000\n",
       "daw           0.000000\n",
       "mixing        0.000000\n",
       "headphones    0.000000\n",
       "vocals        0.000000\n",
       "logic         0.000000\n",
       "got           0.000000\n",
       "production    0.000000\n",
       "samples       0.000000\n",
       "laptop        0.000000\n",
       "fl            0.000000\n",
       "interface     0.000000\n",
       "ableton       0.000000\n",
       "beat          0.000000\n",
       "producer      0.000000\n",
       "effect        0.000000\n",
       "mix           0.000000\n",
       "plugins       0.000000\n",
       "artists       0.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine the 25 words that have the lowest frequency ratio,\n",
    "#i.e. the strongest indicators of \"Producers\" subreddit\n",
    "freq_ratios_df.sort_values('freq_ratio', ascending=False).tail(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e90522a-d8a6-4d43-b82b-391091a9ba4f",
   "metadata": {},
   "source": [
    "Judging by my basic knowledge of music composition and production, the first \"top 25\" list *does* seem to contain mostly words that I would strongly associate with Composition over Production.  Similarly, the second list seems to contain mostly words that I would strongly associate with Production over Composition.  However, there are certainly some surprising exceptions, such as \"love\" and \"feedback\" in the first list and \"got\" in the second list.  This does not mean that these words are poor predictors, though - it's quite possible that e.g. the two subreddits have different cultures, making the word \"love\" much more common in one than the other.\n",
    "\n",
    "If a word in a post's title appears near the top (bottom) of the sorted list of 134 words - of which we saw the top and bottom 25 words - then that post is very likely to have come from the Composers (Producers) subreddit.  However, it is certainly not the case that all posts have one of these words in their titles.  For now, we can ask: of all the posts from either subreddit, how many contain a word in the top or bottom ~25% (top/bottom 34 words out of all 134) of the sorted list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9718fdc-44cb-4294-abc1-756a31a41fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4991394148020654"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = freq_ratios_df.index\n",
    "#Top and bottom ~25.4% of the lists above\n",
    "tops = list(freq_ratios_df.sort_values('freq_ratio', ascending=False).head(34).index)\n",
    "bots = list(freq_ratios_df.sort_values('freq_ratio', ascending=False).tail(34).index)\n",
    "\n",
    "results=[]\n",
    "for ind in df.index:\n",
    "    flag=0\n",
    "    for word in tops + bots:\n",
    "        if word in df.loc[ind, 'title']:\n",
    "            flag=1\n",
    "            break\n",
    "    if flag==1:\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)\n",
    "\n",
    "#Compute the proportion of posts whose titles contain one of these \"top\" or \"bottom\" words\n",
    "res = pd.Series(results)\n",
    "res.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cb4ff4-e9cd-41a6-a50b-28c9701e0ca4",
   "metadata": {},
   "source": [
    "This means that just about half of all posts contain one of the words (\"top\" or \"bottom\" words) that strongly indicate one subreddit or another.  The other half of words do not give us such strong information about the subreddit from which they might have come.  A rough guess thus tells us that a model trained only on the titles of posts, and given access to the word counts only of the 134 words above, would probably classify about 75% of posts correctly.  This assumes the model will automatically be correct about any posts containing a \"top\" or \"bottom\" word in its title, and it will have to guess completely at random in all other cases; obviously this is just an approximation.\n",
    "\n",
    "To see how well such a basic model can perform, we will train a logistic regression model on nothing but the word counts of these 134 in the titles of posts.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbd50385-9d48-4947-877d-db870d6bb346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anyone</th>\n",
       "      <th>audio</th>\n",
       "      <th>band</th>\n",
       "      <th>best</th>\n",
       "      <th>chord</th>\n",
       "      <th>classical</th>\n",
       "      <th>compose</th>\n",
       "      <th>composer</th>\n",
       "      <th>composers</th>\n",
       "      <th>composing</th>\n",
       "      <th>...</th>\n",
       "      <th>using</th>\n",
       "      <th>vocal</th>\n",
       "      <th>vocals</th>\n",
       "      <th>voice</th>\n",
       "      <th>vs</th>\n",
       "      <th>vst</th>\n",
       "      <th>want</th>\n",
       "      <th>way</th>\n",
       "      <th>worth</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zoda66</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Composers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10axn2g</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Composers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xwnm20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Composers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyd8hh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Composers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y03hjd</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Composers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10azzqv</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Producers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109519w</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Producers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zvii8w</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Producers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102f8yv</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Producers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107dyqs</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Producers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1743 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         anyone  audio  band  best  chord  classical  compose  composer  \\\n",
       "id                                                                        \n",
       "zoda66        0      0   0.0     0    0.0        0.0      0.0       0.0   \n",
       "10axn2g       0      0   0.0     0    0.0        0.0      0.0       0.0   \n",
       "xwnm20        0      0   0.0     0    0.0        0.0      0.0       0.0   \n",
       "zyd8hh        0      0   0.0     2    0.0        0.0      0.0       0.0   \n",
       "y03hjd        0      0   0.0     0    0.0        0.0      0.0       0.0   \n",
       "...         ...    ...   ...   ...    ...        ...      ...       ...   \n",
       "10azzqv       0      0   NaN     0    NaN        NaN      NaN       NaN   \n",
       "109519w       0      0   NaN     0    NaN        NaN      NaN       NaN   \n",
       "zvii8w        1      0   NaN     0    NaN        NaN      NaN       NaN   \n",
       "102f8yv       0      0   NaN     0    NaN        NaN      NaN       NaN   \n",
       "107dyqs       0      1   NaN     0    NaN        NaN      NaN       NaN   \n",
       "\n",
       "         composers  composing  ...  using  vocal  vocals  voice   vs  vst  \\\n",
       "id                             ...                                          \n",
       "zoda66         0.0        0.0  ...    NaN    NaN     NaN    NaN  NaN  NaN   \n",
       "10axn2g        0.0        0.0  ...    NaN    NaN     NaN    NaN  NaN  NaN   \n",
       "xwnm20         0.0        0.0  ...    NaN    NaN     NaN    NaN  NaN  NaN   \n",
       "zyd8hh         0.0        0.0  ...    NaN    NaN     NaN    NaN  NaN  NaN   \n",
       "y03hjd         0.0        1.0  ...    NaN    NaN     NaN    NaN  NaN  NaN   \n",
       "...            ...        ...  ...    ...    ...     ...    ...  ...  ...   \n",
       "10azzqv        NaN        NaN  ...    0.0    0.0     0.0    0.0  0.0  0.0   \n",
       "109519w        NaN        NaN  ...    0.0    0.0     0.0    0.0  0.0  0.0   \n",
       "zvii8w         NaN        NaN  ...    0.0    0.0     0.0    0.0  0.0  0.0   \n",
       "102f8yv        NaN        NaN  ...    0.0    0.0     0.0    0.0  0.0  0.0   \n",
       "107dyqs        NaN        NaN  ...    0.0    0.0     0.0    0.0  0.0  0.0   \n",
       "\n",
       "         want  way  worth  subreddit  \n",
       "id                                    \n",
       "zoda66    NaN  NaN    NaN  Composers  \n",
       "10axn2g   NaN  NaN    NaN  Composers  \n",
       "xwnm20    NaN  NaN    NaN  Composers  \n",
       "zyd8hh    NaN  NaN    NaN  Composers  \n",
       "y03hjd    NaN  NaN    NaN  Composers  \n",
       "...       ...  ...    ...        ...  \n",
       "10azzqv   0.0  0.0    0.0  Producers  \n",
       "109519w   0.0  0.0    0.0  Producers  \n",
       "zvii8w    0.0  0.0    0.0  Producers  \n",
       "102f8yv   0.0  0.0    0.0  Producers  \n",
       "107dyqs   0.0  0.0    0.0  Producers  \n",
       "\n",
       "[1743 rows x 135 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make a dataframe of just the 134 top words\n",
    "top_words_df = pd.concat([comps_top_words_df, prods_top_words_df])\n",
    "\n",
    "#Add back the classes to which each observation belongs\n",
    "top_words_df['subreddit'] = df['subreddit']\n",
    "\n",
    "top_words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de19abaa-f126-4387-9c0b-8e2d2c72a63c",
   "metadata": {},
   "source": [
    "As we can see, there are `NaN` values in this table corresponding to words that only appear in at least 1% of \"Composers\" titles but not at least 1% of \"Producers\" titles, and vice-versa.  This means that the proper word count for each of these `NaN` values is simply zero.  So we'll fill in these missing values before proceeding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc5f4552-169c-4117-81b8-ecb679447597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anyone</th>\n",
       "      <th>audio</th>\n",
       "      <th>band</th>\n",
       "      <th>best</th>\n",
       "      <th>chord</th>\n",
       "      <th>classical</th>\n",
       "      <th>compose</th>\n",
       "      <th>composer</th>\n",
       "      <th>composers</th>\n",
       "      <th>composing</th>\n",
       "      <th>...</th>\n",
       "      <th>using</th>\n",
       "      <th>vocal</th>\n",
       "      <th>vocals</th>\n",
       "      <th>voice</th>\n",
       "      <th>vs</th>\n",
       "      <th>vst</th>\n",
       "      <th>want</th>\n",
       "      <th>way</th>\n",
       "      <th>worth</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zoda66</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Composers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10axn2g</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Composers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xwnm20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Composers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyd8hh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Composers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y03hjd</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Composers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         anyone  audio  band  best  chord  classical  compose  composer  \\\n",
       "id                                                                        \n",
       "zoda66        0      0   0.0     0    0.0        0.0      0.0       0.0   \n",
       "10axn2g       0      0   0.0     0    0.0        0.0      0.0       0.0   \n",
       "xwnm20        0      0   0.0     0    0.0        0.0      0.0       0.0   \n",
       "zyd8hh        0      0   0.0     2    0.0        0.0      0.0       0.0   \n",
       "y03hjd        0      0   0.0     0    0.0        0.0      0.0       0.0   \n",
       "\n",
       "         composers  composing  ...  using  vocal  vocals  voice   vs  vst  \\\n",
       "id                             ...                                          \n",
       "zoda66         0.0        0.0  ...    0.0    0.0     0.0    0.0  0.0  0.0   \n",
       "10axn2g        0.0        0.0  ...    0.0    0.0     0.0    0.0  0.0  0.0   \n",
       "xwnm20         0.0        0.0  ...    0.0    0.0     0.0    0.0  0.0  0.0   \n",
       "zyd8hh         0.0        0.0  ...    0.0    0.0     0.0    0.0  0.0  0.0   \n",
       "y03hjd         0.0        1.0  ...    0.0    0.0     0.0    0.0  0.0  0.0   \n",
       "\n",
       "         want  way  worth  subreddit  \n",
       "id                                    \n",
       "zoda66    0.0  0.0    0.0  Composers  \n",
       "10axn2g   0.0  0.0    0.0  Composers  \n",
       "xwnm20    0.0  0.0    0.0  Composers  \n",
       "zyd8hh    0.0  0.0    0.0  Composers  \n",
       "y03hjd    0.0  0.0    0.0  Composers  \n",
       "\n",
       "[5 rows x 135 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_df.fillna(0, inplace=True)\n",
    "top_words_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81028a8-e363-4659-8199-a6073c1d8b10",
   "metadata": {},
   "source": [
    "#### Gridsearch for basic logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41caa784-905e-4d23-8ae6-160645ba3d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = top_words_df.drop(columns='subreddit')\n",
    "y = top_words_df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04b8af8e-4a25-40ab-a06a-3dafb834c7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86d2059b-be7a-4bcf-8b83-669c66fc55b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe_params = {\n",
    "    'lr__C' : np.logspace(-3,3,60)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7754dc0-3cce-43cf-9b12-5233ac20008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid = GridSearchCV(lr_pipe, lr_pipe_params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d257fb5c-4794-448d-8564-55f5a0e07b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'lr__C': array([1.00000000e-03, 1.26384820e-03, 1.59731228e-03, 2.01876025e-03,\n",
       "       2.55140652e-03, 3.22459055e-03, 4.07539297e-03, 5.15067808e-03,\n",
       "       6.50967523e-03, 8.22724134e-03, 1.03979842e-02, 1.31414736e-02,\n",
       "       1.66088278e-02, 2.09910372e-02, 2.65294846...\n",
       "       4.58159767e+00, 5.79044398e+00, 7.31824222e+00, 9.24914728e+00,\n",
       "       1.16895182e+01, 1.47737765e+01, 1.86718109e+01, 2.35983347e+01,\n",
       "       2.98247129e+01, 3.76939098e+01, 4.76393801e+01, 6.02089449e+01,\n",
       "       7.60949669e+01, 9.61724871e+01, 1.21547425e+02, 1.53617495e+02,\n",
       "       1.94149195e+02, 2.45375111e+02, 3.10116893e+02, 3.91940677e+02,\n",
       "       4.95353521e+02, 6.26051657e+02, 7.91234262e+02, 1.00000000e+03])})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f385468-f48b-4cc2-bd96-f4104a45cf17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8450894180416956"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd867e2-e3e7-45dc-8df1-55a2b43e49a2",
   "metadata": {},
   "source": [
    "Keep in mind that this score somewhat *overestimates* the performance of this model.  This is because, to properly use this method, we would need to *make an sklearn transformer* that automatically creates the `top_words_df` to feed into the model; this way the transformer can be separately fit to each of the folds in a gridsearch.  In our case we simply \"fit this transformer\" to *all* of our training data, rather than fitting it to only a random 80% of our training data at a time prior to using the other 20% to evaluate the results.\n",
    "\n",
    "We can make our `freq_ratio` transformer using sklearn's `FunctionTransformer` transformer.  `FunctionTransformer` simply takes a function and turns it into an sklearn transformer!  So we must only write the appropriate transformation *function*:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a448a12-9a34-4863-8731-c1a3a8f7c9e4",
   "metadata": {},
   "source": [
    "## Function to extract words with highest and lowest frequency ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27af5951-d7f4-45bb-a24b-cb4d3ab0398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fr_transform(X, y, text_labels=None, cutoff_freq_ratio=0.0, cutoff_proportion=1.0, cvec_kwargs={}):\n",
    "    '''\n",
    "    NOTE: X and y MUST have a matching Pandas index!  Otherwise this function won't run properly.\n",
    "    \n",
    "    Inputs:\n",
    "    -A Pandas dataframe X of texts (possibly multiple columns of text in each row of X)\n",
    "    -A Pandas series y of exactly TWO classes to which each observation belongs\n",
    "    -A dictionary text_labels whose keys are the names of the various columns of text in X\n",
    "        and whose values are the names we'd like them to be called in the outputted \n",
    "        dataframe's columns.  For example, \n",
    "            {'title':'t', 'text':'b'}).\n",
    "        We count-vectorize the words in the columns separately; e.g. if the \"title\" is\n",
    "        'hello world' and the \"text\" is 'hello happy world' then the resulting columns\n",
    "        will look like t_hello, t_world, b_hello, b_happy, and b_world (using the example\n",
    "        dictionary above).\n",
    "        If no text_labels dictionary is passed, then the columns' separate texts will simply\n",
    "        be treated as parts of one big text: only one word count will be given for each word,\n",
    "        rather than a separate word count for each type (column) of text.\n",
    "    \n",
    "    Parameters:\n",
    "    -cutoff_freq_ratio (float, default 0): After finding the frequency ratio of each word,\n",
    "        keep that word in the outputted dataframe only if its frequency ratio (or the inverse\n",
    "        of its frequency ratio) is at least cutoff_freq_ratio.  For example, setting this to\n",
    "        10 means only those words that are at least 10 times as common in one class as compared\n",
    "        to the other will be kept in the resulting dataframe.\n",
    "    -cutoff_proportion (float, default 1): After finding all frequency ratios and sorting the\n",
    "        words by frequency ratio, keep only those words that appear in the top or bottom \n",
    "        cutoff_proportion proportion of this list.  For example, if cutoff_proportion=.25,\n",
    "        then only the top quarter and bottom quarter of the sorted list will be kept.\n",
    "    -cvec_kwargs: A dictionary of keyword arugments to be passed to CountVectorizer during\n",
    "        the processing.  For example, you can specify stop_words or min_df here, as well\n",
    "        as any custom preprocessing.\n",
    "        \n",
    "    Output:\n",
    "    Separately count-vectorizes the text(s) in each of the two classes.  For each word, calculates\n",
    "    the frequency of that word in each class.  Then takes the ratio of these frequencies for each word\n",
    "    (in each text type, if text_labels are passed) among the two classes.  Then returns a combined\n",
    "    dataframe of the count vectorizations, keeping only those words that meet the cutoff_freq_ratio\n",
    "    or cutoff_proportion (if given).\n",
    "    Here \"words\" can also mean n-grams, if an appropriate ngram_range is passed to cvec_kwargs.\n",
    "    '''\n",
    "    \n",
    "    #Raise errors if given bad inputs\n",
    "    if type(X) == pd.core.series.Series:\n",
    "        raise ValueError(\"X must be a Pandas dataframe, not a series\")\n",
    "    \n",
    "    if len(y.unique()) != 2:\n",
    "        raise ValueError(\"y variable does not have exactly 2 values so can't be used for classification\")\n",
    "        \n",
    "    if cutoff_freq_ratio > 0.0 and cutoff_proportion < .5:\n",
    "        raise ValueError(\"You can specify AT MOST ONE of cutoff_freq_ratio or cutoff_proportion\")\n",
    "        \n",
    "    if text_labels != None:\n",
    "        if set(text_labels.keys()) != set(X.columns):\n",
    "            raise ValueError(\"The keys of text_labels must match the names of the columns in X\")\n",
    "            \n",
    "    \n",
    "    #Make a column that concatenates (with spaces) the texts of all the text columns\n",
    "    #This will be useful in case text_labels is not given\n",
    "    X['%combined%']=X.apply((lambda x : ' '.join(x)), axis=1)\n",
    "    \n",
    "    #Split data by classes\n",
    "    classes = list(y.unique())\n",
    "    class0 = classes[0]\n",
    "    class1 = classes[1]\n",
    "    \n",
    "    #Make dataframes of X separately for each class\n",
    "    c0 = X[y==class0]\n",
    "    c1 = X[y==class1]\n",
    "    \n",
    "    \n",
    "    #Make vectorizers of all words (cv_all), or just words with a certain min_df, max_df, etc. (cv_top)\n",
    "    problem_kws = {'min_df', 'max_df', 'max_features'}\n",
    "    all_args_dict = {key:value for (key, value) in cvec_kwargs.items() if key not in problem_kws}\n",
    "    top_args_dict = cvec_kwargs\n",
    "    \n",
    "    cv_all = CountVectorizer(**all_args_dict)\n",
    "    cv_top = CountVectorizer(**top_args_dict)\n",
    "    \n",
    "    #Find word counts\n",
    "    \n",
    "    \n",
    "    #IF text_labels WERE NOT GIVEN:\n",
    "    #Use the '%combined%' column\n",
    "    if text_labels==None:\n",
    "\n",
    "        #Make dataframes\n",
    "        c0_top_words = cv_top.fit_transform(c0['%combined%'])\n",
    "        c0_top_words_df = pd.DataFrame(c0_top_words.todense(), columns=cv_top.get_feature_names_out(), index=c0.index)\n",
    "    \n",
    "        c1_top_words = cv_top.fit_transform(c1['%combined%'])\n",
    "        c1_top_words_df = pd.DataFrame(c1_top_words.todense(), columns=cv_top.get_feature_names_out(), index=c1.index)\n",
    "        \n",
    "        c0_all_words = cv_all.fit_transform(c0['%combined%'])\n",
    "        c0_all_words_df = pd.DataFrame(c0_all_words.todense(), columns=cv_all.get_feature_names_out(), index=c0.index)\n",
    "    \n",
    "        c1_all_words = cv_all.fit_transform(c1['%combined%'])\n",
    "        c1_all_words_df = pd.DataFrame(c1_all_words.todense(), columns=cv_all.get_feature_names_out(), index=c1.index)\n",
    "        \n",
    "        #Find frequencies\n",
    "        words_to_check = set(list(c0_top_words_df.columns) + list(c1_top_words_df.columns))\n",
    "\n",
    "        words = []\n",
    "        freq_ratios = []\n",
    "\n",
    "        #Loop over each word to find its frequency\n",
    "        for word in words_to_check:\n",
    "            #If the word only appears in the c1 data (not in c0), set freq_ratio=0\n",
    "            if word not in c0_all_words_df.columns:\n",
    "                freq_ratio = 0\n",
    "        \n",
    "            #If the word only appears in the c0 data (not in c1), set freq_ratio=infinity\n",
    "            elif word not in c1_all_words_df.columns:\n",
    "                freq_ratio = np.inf\n",
    "    \n",
    "            #If the word appears in both, take the ratio of frequencies\n",
    "            else:\n",
    "                c0_freq = c0_all_words_df.sum()[word]/len(c0)\n",
    "                c1_freq = c1_all_words_df.sum()[word]/len(c1)\n",
    "                freq_ratio = c0_freq / c1_freq\n",
    "    \n",
    "            words.append(word)\n",
    "            freq_ratios.append(freq_ratio)\n",
    "        \n",
    "        #Make frequency ratios into a dataframe indexed by the words\n",
    "        freq_ratios_df = pd.DataFrame(freq_ratios, index=words)\n",
    "        freq_ratios_df.columns = ['freq_ratio']\n",
    "        \n",
    "        \n",
    "\n",
    "        #Remove words that don't meet the specified cutoff\n",
    "        #1: cutoff_freq_ratio\n",
    "        if cutoff_freq_ratio > 0.0:\n",
    "            cutoff = cutoff_freq_ratio\n",
    "            inv_cutoff = 1/(cutoff_freq_ratio)\n",
    "            words_to_keep = []\n",
    "            for word in freq_ratios_df.index:\n",
    "                #If the frequency ratio is bigger than the cutoff or smaller than the inverse of the cutoff,\n",
    "                #then we'll keep this word.  Otherwise we won't\n",
    "                if (freq_ratios_df['freq_ratio'][word]>cutoff) or (freq_ratios_df['freq_ratio'][word]<inv_cutoff):\n",
    "                    words_to_keep.append(word)\n",
    "                    \n",
    "        #2: cutoff_proportion\n",
    "        elif cutoff_proportion < 0.5:\n",
    "            sorted_freq_ratios_df = freq_ratios_df.sort_values('freq_ratio', ascending=False)\n",
    "            n_tops = int(np.floor( len(sorted_freq_ratios_df)*cutoff_proportion ))\n",
    "            tops = sorted_freq_ratios_df.head(n_tops).index\n",
    "            bots = sorted_freq_ratios_df.tail(n_tops).index\n",
    "            words_to_keep = list(tops)+list(bots)\n",
    "        \n",
    "        #If no cutoffs were given, keep all the words that weren't eliminated by CountVectorizer already\n",
    "        else:\n",
    "            words_to_keep = list(freq_ratios_df.index)\n",
    "            \n",
    "\n",
    "        \n",
    "        #Make a dataframe of all the words not eliminated by CountVectorizer already\n",
    "        top_words_df = pd.concat([c0_top_words_df, c1_top_words_df])\n",
    "\n",
    "        #Keep only those words that meet the specified cutoff\n",
    "        top_words_df = top_words_df[words_to_keep]\n",
    "\n",
    "        #Missing values correspond to zero appearances of a word, so fill them with zeros\n",
    "        top_words_df.fillna(0, inplace=True)\n",
    "        \n",
    "        return top_words_df\n",
    "        \n",
    "        \n",
    "        \n",
    "    #Still need to add functionality for the following.  \n",
    "    \n",
    "    #IF text_labels WERE GIVEN:\n",
    "    #vectorize each text column separately                   \n",
    "    else:\n",
    "        #Initialize a list of word count dataframes\n",
    "        counts_dfs = []\n",
    "        \n",
    "        for (col, cnum, kind) in itertools.product(X.columns, ['0', '1'], ['top','all']):\n",
    "            #Don't vectorize the combined column we made\n",
    "            if col=='%combined%':\n",
    "                continue\n",
    "            \n",
    "            #Get abbreviated column labels from text_labels\n",
    "            l = text_labels[col]\n",
    "            \n",
    "            #Make c0_top_title, c1_all_body, etc.\n",
    "            locals()[f\"c{cnum}_{kind}_{l}\"] = locals()[f\"cv_{kind}\"].fit_transform(locals()[f\"c{cnum}\"][col])\n",
    "            locals()[f\"c{cnum}_{kind}_{l}_df\"] = pd.DataFrame(locals()[f\"c{cnum}_{kind}_{l}\"].todense(),\n",
    "                                                              columns = locals()[f\"cv_{kind}\"].get_feature_names_out(),\n",
    "                                                              index = locals()[f\"c{cnum}\"].index\n",
    "                                                             )\n",
    "            #Add the t_ or b_ to the names of the columns (words)\n",
    "            locals()[f\"c{cnum}_{kind}_{l}_df\"] = locals()[f\"c{cnum}_{kind}_{l}_df\"].add_prefix(f\"{l}_\")\n",
    "            \n",
    "            \n",
    "            \n",
    "        #Still need to add functionality for when text_labels are given.\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce11676-8fd1-4654-94b5-e3287834e916",
   "metadata": {},
   "source": [
    "## Testing the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d210cb-0ffa-48ee-8213-7e0b87c63a8e",
   "metadata": {},
   "source": [
    "Here we'll try to replicate the process of dropping those words that appear in the titles of fewer than 1% of \"Composers\" posts and \"Producers\" posts - but this time, using the function we wrote!  Note that this exercise doesn't actually employ the frequency ratios calculated by the function; in order to use these, we have to pass a `cutoff_freq_ratio` or a `cutoff_proportion` to the function.  In any case, we found that there were 134 words that were in at least 1% of posts' titles, so if things are working correctly then we should have 134 columns in the resulting dataframe below.  We should also have 1743 rows, corresponding to the 1743 observations in our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1970c17-c69f-4925-8893-a65142c12519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replicating our previous work, but this time using the function\n",
    "X = df[['title']]\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60f47a4f-0e94-429a-8c28-bef48d41de7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1743, 134)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fugue</th>\n",
       "      <th>quartet</th>\n",
       "      <th>used</th>\n",
       "      <th>someone</th>\n",
       "      <th>need</th>\n",
       "      <th>minor</th>\n",
       "      <th>flute</th>\n",
       "      <th>learn</th>\n",
       "      <th>mixing</th>\n",
       "      <th>please</th>\n",
       "      <th>...</th>\n",
       "      <th>string</th>\n",
       "      <th>want</th>\n",
       "      <th>time</th>\n",
       "      <th>orchestra</th>\n",
       "      <th>mic</th>\n",
       "      <th>vocal</th>\n",
       "      <th>anyone</th>\n",
       "      <th>trying</th>\n",
       "      <th>making</th>\n",
       "      <th>artists</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103osx2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zznfx9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fugue  quartet  used  someone  need  minor  flute  learn  mixing  \\\n",
       "id                                                                          \n",
       "103osx2    0.0      0.0   0.0      0.0     0    0.0    0.0    0.0     0.0   \n",
       "zznfx9     0.0      0.0   0.0      0.0     0    0.0    0.0    0.0     0.0   \n",
       "\n",
       "         please  ...  string  want  time  orchestra  mic  vocal  anyone  \\\n",
       "id               ...                                                      \n",
       "103osx2       0  ...     0.0   0.0     0        0.0  0.0    0.0       0   \n",
       "zznfx9        0  ...     0.0   0.0     0        0.0  0.0    0.0       0   \n",
       "\n",
       "         trying  making  artists  \n",
       "id                                \n",
       "103osx2     0.0     0.0      0.0  \n",
       "zznfx9      0.0     0.0      0.0  \n",
       "\n",
       "[2 rows x 134 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1 = fr_transform(X, y,\n",
    "                     cvec_kwargs={'stop_words' : stopwords.words('english'),\n",
    "                     'preprocessor' : (lambda x : url_preprocessor(x)),\n",
    "                     'min_df' : .01\n",
    "             })\n",
    "#Function returns result dataframe as first output and also spits back y as second output\n",
    "res1 = result1\n",
    "\n",
    "print(res1.shape)\n",
    "res1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a706f16-642f-4a1d-afad-c7dd48fefe8b",
   "metadata": {},
   "source": [
    "### Using `cutoff_proportion` to replicate the above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9cecb9-1313-4ed5-8028-32bdb4afc781",
   "metadata": {},
   "source": [
    "Above, we looked at the top 25 and bottom 25 words from our (134-word) dataframe that was sorted by frequency ratio.  Since `25 == floor(.187*134)`, we should get back these same 50 words by setting a `cutoff_proportion` equal to .187 in our function.  So if things are running correctly, then the resulting dataframe below should have the same 50 words we saw before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3773de2-03f8-4e2f-9e2f-56a2c73de712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1743, 50)\n",
      "['artists', 'mic', 'laptop', 'daw', 'got', 'samples', 'mix', 'interface', 'production', 'vocals', 'headphones', 'ableton', 'plugins', 'logic', 'beat', 'producer', 'effect', 'fl', 'mixing', 'midi', 'beats', 'synth', 'vocal', 'sample', 'producers', 'musescore', 'string', 'movement', 'quartet', 'short', 'wrote', 'composing', 'feedback', 'love', 'flute', 'piece', 'concerto', 'minor', 'orchestra', 'violin', 'score', 'theme', 'composition', 'wind', 'symphony', 'prelude', 'sonata', 'composer', 'quintet', 'fugue']\n"
     ]
    }
   ],
   "source": [
    "result2 = fr_transform(X, y,\n",
    "                       cutoff_proportion = .187,\n",
    "                     cvec_kwargs={'stop_words' : stopwords.words('english'),\n",
    "                     'preprocessor' : (lambda x : url_preprocessor(x)),\n",
    "                     'min_df' : .01\n",
    "             })\n",
    "\n",
    "#This should have 68 columns if things are working correctly.\n",
    "print(result2.shape)\n",
    "\n",
    "print(list(result2.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b81696a-cc38-47d0-a771-86bbb56703b2",
   "metadata": {},
   "source": [
    "### Using `cutoff_freq_ratio` to find the strongest bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e0d340-021d-4f1f-975a-9c8dc2aded6c",
   "metadata": {},
   "source": [
    "This time, let's use the function to produce only those bigrams that are at least 10 times as common among \"Composers\" titles as among \"Producers\" titles, or at least 10 times as common among \"Producers\" titles as among \"Composers\" titles.  We'll leave it to the reader to guess which bigrams tend to come from which subreddit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ef11a04-9bcb-49e7-9bcf-05d2a0f61766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1743, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original composition</th>\n",
       "      <th>looking feedback</th>\n",
       "      <th>music production</th>\n",
       "      <th>fl studio</th>\n",
       "      <th>piano piece</th>\n",
       "      <th>string quartet</th>\n",
       "      <th>audio interface</th>\n",
       "      <th>love feedback</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103osx2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zznfx9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         original composition  looking feedback  music production  fl studio  \\\n",
       "id                                                                             \n",
       "103osx2                   0.0               0.0               0.0        0.0   \n",
       "zznfx9                    0.0               0.0               0.0        0.0   \n",
       "\n",
       "         piano piece  string quartet  audio interface  love feedback  \n",
       "id                                                                    \n",
       "103osx2          0.0             0.0              0.0            0.0  \n",
       "zznfx9           0.0             0.0              0.0            0.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3 = fr_transform(X, y,\n",
    "                       cutoff_freq_ratio = 10,\n",
    "                     cvec_kwargs={'stop_words' : stopwords.words('english'),\n",
    "                     'preprocessor' : (lambda x : url_preprocessor(x)),\n",
    "                     'min_df' : .01,\n",
    "                     'ngram_range' : (2,2)\n",
    "             })\n",
    "\n",
    "print(result3.shape)\n",
    "result3.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014a1ec6-841d-4c3d-a3e7-f654061cd491",
   "metadata": {},
   "source": [
    "# Using `fr_transform` to make a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496f1135-2b5a-4ac1-bfde-4a3a994f6b11",
   "metadata": {},
   "source": [
    "### Train/test split\n",
    "\n",
    "Recall that we reserved 20% of our original data in the `val_df` dataframe.  We will use this data *only for validation, at the very end of the modeling process*.  So to test the performance of models that we build, we will need to perform additional train/test splits.\n",
    "\n",
    "Additionally, we will now use both the titles and body texts of the reddit posts in order to build our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e41f61b-efb4-4a41-ad48-6a7abd882cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['title']]\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5db3f2e-2f7c-4108-80fb-3f8ea9551048",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49409a37-3b54-4a8b-967e-508505ac25e3",
   "metadata": {},
   "source": [
    "### Transform training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e692cc6-55bf-44d9-a54a-0dfc1fd05e5d",
   "metadata": {},
   "source": [
    "We can use the `fr_transform` function we wrote to easily transform our training data.  This time, let's use it to keep only those words that are at least *5 times as common among one subreddit as compared to the other*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7bda8167-3c4c-4b21-9477-1b06ac71592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_kwargs = {'stop_words' : stopwords.words('english'),\n",
    "                  'preprocessor' : (lambda x : url_preprocessor(x)),\n",
    "                  'min_df' : .01\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0fe0244a-10b1-4682-b3b4-ba4bf776ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans = fr_transform(X_train, y_train,\n",
    "                             cutoff_freq_ratio = 0.0,\n",
    "                             cvec_kwargs = cvec_kwargs\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51e01ac6-642b-4075-b422-ae54871caedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1725, 134)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fugue</th>\n",
       "      <th>quartet</th>\n",
       "      <th>used</th>\n",
       "      <th>someone</th>\n",
       "      <th>minor</th>\n",
       "      <th>need</th>\n",
       "      <th>flute</th>\n",
       "      <th>learn</th>\n",
       "      <th>mixing</th>\n",
       "      <th>please</th>\n",
       "      <th>...</th>\n",
       "      <th>string</th>\n",
       "      <th>want</th>\n",
       "      <th>time</th>\n",
       "      <th>orchestra</th>\n",
       "      <th>mic</th>\n",
       "      <th>vocal</th>\n",
       "      <th>anyone</th>\n",
       "      <th>trying</th>\n",
       "      <th>making</th>\n",
       "      <th>artists</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y3fi32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg7loi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fugue  quartet  used  someone  minor  need  flute  learn  mixing  \\\n",
       "id                                                                         \n",
       "y3fi32    0.0      0.0   0.0      0.0    0.0     0    0.0    0.0     0.0   \n",
       "xg7loi    0.0      0.0   0.0      0.0    0.0     0    0.0    0.0     0.0   \n",
       "\n",
       "        please  ...  string  want  time  orchestra  mic  vocal  anyone  \\\n",
       "id              ...                                                      \n",
       "y3fi32       0  ...     0.0   0.0     0        0.0  0.0    0.0       2   \n",
       "xg7loi       0  ...     0.0   0.0     0        0.0  0.0    0.0       0   \n",
       "\n",
       "        trying  making  artists  \n",
       "id                               \n",
       "y3fi32     0.0     0.0      0.0  \n",
       "xg7loi     0.0     0.0      0.0  \n",
       "\n",
       "[2 rows x 134 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train_trans.shape)\n",
    "X_train_trans.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f10e58c-d9b9-430e-a57f-109cdbf199b5",
   "metadata": {},
   "source": [
    "So these are the words that are at least 5 times as common among one subreddit as compared to the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7174a1bb-ff44-42ee-9825-29e85dae5d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can anyone recommend any good free composing apps/software?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2.0, 'free'),\n",
       " (2.0, 'good'),\n",
       " (2.0, 'composing'),\n",
       " (2.0, 'software'),\n",
       " (2.0, 'anyone')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 'y3fi32'\n",
    "print(df.loc[ind,:]['title'])\n",
    "[(X_train_trans.loc[ind,:][i], i) for i in X_train_trans.loc[ind,:].index if X_train_trans.loc[ind,:][i] != 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e75bc206-a2ec-4cd0-b391-28caa897c16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there somebody who can tell me the best way to post a score?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2.0, 'best'), (2.0, 'score')]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 'xg7loi'\n",
    "print(df.loc[ind,:]['title'])\n",
    "[(X_train_trans.loc[ind,:][i], i) for i in X_train_trans.loc[ind,:].index if X_train_trans.loc[ind,:][i] != 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd5b2c2-62a8-4d53-ac00-a50cc67cdd1a",
   "metadata": {},
   "source": [
    "### Transform test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d480ef-f7f2-4d11-9737-39ac437b7fc8",
   "metadata": {},
   "source": [
    "Now that we've transformed our training data, we need to perform the *same transformation on the $X$-values of our test data*.  We do so below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0afd8a89-faaf-4e62-8289-af7d95402e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 105)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setting</th>\n",
       "      <th>quartet</th>\n",
       "      <th>apollo</th>\n",
       "      <th>file</th>\n",
       "      <th>layer</th>\n",
       "      <th>cascades</th>\n",
       "      <th>twin</th>\n",
       "      <th>atm</th>\n",
       "      <th>cinematic</th>\n",
       "      <th>input</th>\n",
       "      <th>...</th>\n",
       "      <th>akg</th>\n",
       "      <th>computer</th>\n",
       "      <th>well</th>\n",
       "      <th>bit</th>\n",
       "      <th>time</th>\n",
       "      <th>mic</th>\n",
       "      <th>vocal</th>\n",
       "      <th>mostly</th>\n",
       "      <th>shimmering</th>\n",
       "      <th>guys</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107nywp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zru4o5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         setting  quartet  apollo  file  layer  cascades  twin  atm  \\\n",
       "id                                                                    \n",
       "107nywp      0.0      0.0     0.0   0.0    0.0       0.0   0.0  1.0   \n",
       "zru4o5       0.0      1.0     0.0   0.0    0.0       1.0   0.0  0.0   \n",
       "\n",
       "         cinematic  input  ...  akg  computer  well  bit  time  mic  vocal  \\\n",
       "id                         ...                                               \n",
       "107nywp        0.0    0.0  ...  0.0       0.0   0.0  0.0   0.0  0.0    0.0   \n",
       "zru4o5         0.0    0.0  ...  0.0       0.0   0.0  0.0   0.0  0.0    0.0   \n",
       "\n",
       "         mostly  shimmering  guys  \n",
       "id                                 \n",
       "107nywp     0.0         0.0   1.0  \n",
       "zru4o5      0.0         1.0   0.0  \n",
       "\n",
       "[2 rows x 105 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize a meaningless series of \"class names\" just so we can pass them to fr_transform\n",
    "y_random_list = [1 if x%2==0 else 0 for x in range(len(X_test))]\n",
    "y_random = pd.Series(y_random_list, index=X_test.index)\n",
    "\n",
    "#Use the same keyword arguments as we did for our training data, except this time make sure to\n",
    "#capture ALL non-stopword words.  We'll filter them manually later on.\n",
    "problem_kws = {'min_df', 'max_df', 'max_features'}\n",
    "test_cvec_kwargs = {key:value for (key, value) in cvec_kwargs.items() if key not in problem_kws}\n",
    "\n",
    "#fr_transform doesn't use the class information as long as cutoff_freq_ratio and cutoff_proportion\n",
    "#are not specified.  So we can just use fr_transform to conveniently transform our X_test data:\n",
    "X_test_trans = fr_transform(X_test, y_random, cvec_kwargs = test_cvec_kwargs)\n",
    "print(X_test_trans.shape)\n",
    "X_test_trans.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0ab154-d75a-47a0-aad5-4e4ab0b83a13",
   "metadata": {},
   "source": [
    "Notice that this `X_test_trans` does *not* have the same columns as our `X_train_trans` dataframe.  So in order for the test data to be compatible with the training data, we have to (1) remove any columns in `X_test_trans` that are not found in `X_train_trans`, then (2) add a column of zeros to `X_test_trans` for every word in `X_train_trans` that wasn't already in `X_test_trans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "23a46e32-dc2f-4804-84e2-eaa591156146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>get</th>\n",
       "      <th>help</th>\n",
       "      <th>quartet</th>\n",
       "      <th>using</th>\n",
       "      <th>plugin</th>\n",
       "      <th>fl</th>\n",
       "      <th>beat</th>\n",
       "      <th>make</th>\n",
       "      <th>got</th>\n",
       "      <th>mixing</th>\n",
       "      <th>...</th>\n",
       "      <th>time</th>\n",
       "      <th>piece</th>\n",
       "      <th>mic</th>\n",
       "      <th>vocal</th>\n",
       "      <th>sound</th>\n",
       "      <th>synth</th>\n",
       "      <th>first</th>\n",
       "      <th>good</th>\n",
       "      <th>vs</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107nywp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zru4o5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         get  help  quartet  using  plugin   fl  beat  make  got  mixing  ...  \\\n",
       "id                                                                        ...   \n",
       "107nywp  0.0   0.0      0.0    0.0     0.0  2.0   0.0   0.0  1.0     0.0  ...   \n",
       "zru4o5   0.0   0.0      1.0    0.0     0.0  0.0   0.0   0.0  0.0     0.0  ...   \n",
       "\n",
       "         time  piece  mic  vocal  sound  synth  first  good   vs  best  \n",
       "id                                                                      \n",
       "107nywp   0.0    0.0  0.0    0.0    0.0    0.0    0.0   0.0  0.0   0.0  \n",
       "zru4o5    0.0    0.0  0.0    0.0    0.0    0.0    0.0   0.0  0.0   0.0  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cols = set(X_train_trans.columns)\n",
    "test_cols = set(X_test_trans.columns)\n",
    "cols_to_keep = list(train_cols.intersection(test_cols))\n",
    "\n",
    "#Drop the columns that don't appear in X_train_trans\n",
    "X_test_trans = X_test_trans[cols_to_keep]\n",
    "X_test_trans.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "201ebc8b-9f21-410a-af3b-dd104736a45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>get</th>\n",
       "      <th>help</th>\n",
       "      <th>quartet</th>\n",
       "      <th>using</th>\n",
       "      <th>plugin</th>\n",
       "      <th>fl</th>\n",
       "      <th>beat</th>\n",
       "      <th>make</th>\n",
       "      <th>got</th>\n",
       "      <th>mixing</th>\n",
       "      <th>...</th>\n",
       "      <th>live</th>\n",
       "      <th>notation</th>\n",
       "      <th>keyboard</th>\n",
       "      <th>string</th>\n",
       "      <th>want</th>\n",
       "      <th>orchestra</th>\n",
       "      <th>anyone</th>\n",
       "      <th>trying</th>\n",
       "      <th>making</th>\n",
       "      <th>artists</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107nywp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zru4o5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         get  help  quartet  using  plugin   fl  beat  make  got  mixing  ...  \\\n",
       "id                                                                        ...   \n",
       "107nywp  0.0   0.0      0.0    0.0     0.0  2.0   0.0   0.0  1.0     0.0  ...   \n",
       "zru4o5   0.0   0.0      1.0    0.0     0.0  0.0   0.0   0.0  0.0     0.0  ...   \n",
       "\n",
       "         live  notation  keyboard  string  want  orchestra  anyone  trying  \\\n",
       "id                                                                           \n",
       "107nywp   0.0       0.0       0.0     0.0   0.0        0.0     0.0     0.0   \n",
       "zru4o5    0.0       0.0       0.0     0.0   0.0        0.0     0.0     0.0   \n",
       "\n",
       "         making  artists  \n",
       "id                        \n",
       "107nywp     0.0      0.0  \n",
       "zru4o5      0.0      0.0  \n",
       "\n",
       "[2 rows x 134 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add in the remaining columns from X_train_trans, filled with zeros since these words\n",
    "#didn't appear in any of the test data posts\n",
    "remaining_cols = list(train_cols - test_cols)\n",
    "for col in remaining_cols:\n",
    "    X_test_trans[col] = 0.0\n",
    "    \n",
    "X_test_trans.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad14cbfe-70ea-489e-a3a1-946252c7acfe",
   "metadata": {},
   "source": [
    "## Fitting and evaluating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "025ab35d-ef26-4c3b-a2c3-906043c8b90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_pipe = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "54c2dd36-90a0-4d58-b39c-62de9b66b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_pipe_params = {\n",
    "    'lr__C' : np.logspace(-6,4,100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4d00082e-d2c5-429f-97e0-d8c72a668273",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_gs = GridSearchCV(logit_pipe, logit_pipe_params, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d64680c0-02dd-476d-991c-d715fa8bdf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'lr__C': array([1.00000000e-06, 1.26185688e-06, 1.59228279e-06, 2.00923300e-06,\n",
       "       2.53536449e-06, 3.19926714e-06, 4.03701726e-06, 5.09413801e-06,\n",
       "       6.42807312e-06, 8.11130831e-06, 1.02353102e-05, 1.29154967e-05,\n",
       "       1.62975083e-05, 2.05651231e-05, 2.59502421...\n",
       "       4.75081016e+01, 5.99484250e+01, 7.56463328e+01, 9.54548457e+01,\n",
       "       1.20450354e+02, 1.51991108e+02, 1.91791026e+02, 2.42012826e+02,\n",
       "       3.05385551e+02, 3.85352859e+02, 4.86260158e+02, 6.13590727e+02,\n",
       "       7.74263683e+02, 9.77009957e+02, 1.23284674e+03, 1.55567614e+03,\n",
       "       1.96304065e+03, 2.47707636e+03, 3.12571585e+03, 3.94420606e+03,\n",
       "       4.97702356e+03, 6.28029144e+03, 7.92482898e+03, 1.00000000e+04])})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_gs.fit(X_train_trans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "78952991-d439-4449-9a70-3e70e461a8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'lr__C': 0.0005336699231206307}, 0.535072463768116)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_logit = logit_gs.best_estimator_\n",
    "logit_gs.best_params_, logit_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e304217a-d897-429e-8e25-2c2f0e76319d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_logit.score(X_test_trans, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9510fa-2901-46f4-91e4-8ff8690a5e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce7fcf-0ba1-4c21-a3fb-641067a65b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee2af87-ee64-43af-8ee7-b8ecb6fcd4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0758cb00-81fa-4501-ad87-ac80121b1a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e87714-eade-4f53-ae1d-2978dd1c5048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63f68fb-81cc-478c-b7f7-a6a6f1531c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d00f7f2-f9b5-4958-bab9-c6f803c30664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ed527-ede4-49da-b5bb-5aad1bca5e31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a08af-0825-407f-81a7-8cfb3c2d8ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d0309a-5f3a-471d-890e-f42bb7c3a5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace68bb8-157c-4402-ae2e-e0f8bb481891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3301328f-7dce-41a8-ae4c-b334910c8067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a2960c-4f20-4ad3-8dda-ee3b39b30d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576bc881-8025-4b90-a6d2-8e5b99625ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08834aab-cd37-45bf-8db2-edaf30186f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c881a-d0af-4b5f-b6d0-e3e1016f39c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038429f-3da3-461a-82d0-a00045f19991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948615f1-0111-4117-ae1c-bb4d9ccc1a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f2feaa-6fea-441e-bc2e-af02537f40cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6b4ba80-38d0-4944-81cc-b9b1993c96d5",
   "metadata": {},
   "source": [
    "## Using the function in a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd763d3-58fb-4c84-a544-ebf6ab44adc1",
   "metadata": {},
   "source": [
    "Since the `fr_transform` function has to look at the $y$-values of our data, it doesn't fit cleanly in an sklearn `Pipeline`.  As far as I can tell, sklearn transformers are not built to be able to look at $y$ even during \"fitting.\"  For example, the [source code for `FunctionTransformer`](https://github.com/scikit-learn/scikit-learn/blob/98cf537f5/sklearn/preprocessing/_function_transformer.py#L20) even says, under the `fit(X, y=None)` method's docstring, that `y : Ignored`.  It seems that sklearn transformers' `.fit` methods only take a `y` argument for consistency with sklearn estimators (which certainly must use $y$) - not because they are allowed to actually look at $y$.  This seems to contradict what [the documentation for `FunctionTransformer` says](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer): \"A FunctionTransformer forwards its X (and optionally y) arguments to a user-defined function...\"\n",
    "\n",
    "In any case, this means that we will have to write yet another custom function in order to be able to apply the `fr_transform` function in a grid search for optimal hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "efdd7038-8013-4072-9b86-1edbc1ac46cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_gridsearch(X, y, est_pipe, est_params, fr_params, cv):\n",
    "    '''\n",
    "    Inputs:\n",
    "    -A Pandas dataframe X\n",
    "    -A Pandas series y\n",
    "    -An sklearn Pipeline estimator est_pipe\n",
    "    -A dictionary est_params of parameters for that Pipeline estimator\n",
    "        (in the usual Pipeline notation)\n",
    "    -A dictionary fr_params of hyperparameters for the fr_transform function\n",
    "    \n",
    "    Parameters:\n",
    "    gs_kwargs: A dictionary of keyword arguments to pass to GridSearchCV\n",
    "    \n",
    "    Outputs:\n",
    "    -A dictionary of dictionaries\n",
    "    \n",
    "    Does:\n",
    "    Loops over each combination of fr_transform hyperparameters.\n",
    "    For each one, performs GridSearchCV using est_pipe and est_params.\n",
    "    Checks whether the best crossval score (across all est_params) for this\n",
    "    combination of fr_transform hyperparameters is better than any other\n",
    "    crossval score for a different combination of fr_transform hyperparameters\n",
    "    tried so far.  If so, updates the \"best cv score so far\" to equal the\n",
    "    current cv score, and also updates the \"best fr_transform hyperparameters\"\n",
    "    and \"best pipeline estimator hyperparameters\" to the current values and\n",
    "    update\n",
    "    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d582ccf-5bfd-491e-812e-fafd503d0008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73c72a96-2c12-4672-8d85-040c83de5284",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cv', CountVectorizer(stop_words='english')),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ef580ea-d88c-422d-8b93-2124c9164a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'lr__C' : 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "efc1aed0-0584-49fa-bea2-a72973248610",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 1743]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5v/3x2_29n942n4k09n89jp09m80000gn/T/ipykernel_44676/146570639.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1506\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m   1509\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 1743]"
     ]
    }
   ],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8aa7e0-6e09-4cfb-834e-233420fe9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X, y, fit_params=pipe_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4529964e-b9b7-4e96-a589-a7a6932faba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03009989-ab73-46bc-a633-42467a3248ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c168978d-10a5-4a69-8365-3a7117a43779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dfae2b-6c94-481d-86e3-e949018dd1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a99b36f-172d-4d9e-897c-20bfb14f9929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1192057f-faa8-457d-ac59-e9fc6a5b5c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8a87f3-64f1-413b-8ab0-514cc227fe0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe60262-8cad-4e7f-aa48-4461857e7df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e04d503-201d-42b5-8001-a2654b370634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f1de9c-f926-436f-aeb3-a1f89736bbd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0452a975-8931-4c12-ad39-a3fb51431994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd36986-4fba-4db4-8f58-ed653b50aaaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba1585-0406-499a-ac94-6cb603f714ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67924c3-b9a6-464c-8b91-2668252978c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43c578e1-52d2-4f98-9e5c-c0e2781de863",
   "metadata": {},
   "source": [
    "## `fr_transform` in a pipeline: Using `FunctionTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805456d5-0140-4f72-a871-e76157d9d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('fr', FunctionTransformer2(lambda args: fr_transform(*args)) ),\n",
    "    ('logit', LogisticRegression())\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c95ede4-1a7c-4512-b104-f328eb22cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51221cb6-2ead-4775-9e03-6cb50c1ea72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'fr__kw_args':[{\n",
    "        'cutoff_freq_ratio':0.0,\n",
    "        'cvec_kwargs':{\n",
    "            'stop_words' : stopwords.words('english'),\n",
    "            'preprocessor' : (lambda x : url_preprocessor(x)),\n",
    "            'min_df' : .01\n",
    "        }\n",
    "    }],\n",
    "    \n",
    "    'logit__C': np.logspace(-3,3,60)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548c4eed-e643-4440-9e8a-a986f0d57614",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipe, pipe_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6677ed73-d028-46c8-bd5e-0597fbe145bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a486612-4f68-48a2-bf56-92cbeca59be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b78c273-b2fe-463e-a240-0f8f7f2bca0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166739ac-c51a-4217-9407-e33a23a96921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714eb287-409e-47e0-b17e-358c73f13fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c243535-8fed-4ba9-991c-78d0e7e81264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
